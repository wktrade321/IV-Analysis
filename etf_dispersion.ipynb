{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import relative_value as rv\n",
    "import requests\n",
    "from urllib.parse import unquote\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from pyetfdb_scraper import etf\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module = 'pyetfdb_scraper')\n",
    "warnings.filterwarnings(\"ignore\", module = 'pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_barchart(url: str, api_method: str, params: dict):\n",
    "    geturl=url\n",
    "    apiurl=f'https://www.barchart.com/proxies/core-api/v1/{api_method}'\n",
    "    \n",
    "    getheaders={\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'cache-control': 'max-age=0',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        \"referer\":url,\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36'\n",
    "        }\n",
    "    \n",
    "    s=requests.Session()\n",
    "    r=s.get(geturl, headers=getheaders)\n",
    "    headers={\n",
    "        'accept': 'application/json',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'user-agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36\",\n",
    "        'x-xsrf-token': unquote(unquote(s.cookies.get_dict()['XSRF-TOKEN']))\n",
    "    }\n",
    "    \n",
    "    r=s.get(apiurl,params=params,headers=headers)\n",
    "    return pd.DataFrame(r.json()['data']).set_index('symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_etf_holdings(yahoo_screen: str, n: int=200, volume_threshold: int=1_000_000):\n",
    "    \"\"\" returns dict of dfs and list of all holdings\"\"\"\n",
    "\n",
    "    etf_list = rv.scrape_yahoo_screener(yahoo_screen)['Symbol'].to_list()[:n]\n",
    "    \n",
    "    holdings_dict = {}\n",
    "    all_holdings = []\n",
    "\n",
    "    for ticker in tqdm(etf_list):\n",
    "        print(ticker)\n",
    "        bc_params = {\n",
    "                \"composite\":ticker,\n",
    "                 \"fields\":\"symbol,symbolName,percent\",\n",
    "                 \"orderBy\":\"percent\",\"orderDir\":\"desc\"\n",
    "                 }\n",
    "        init = etf.ETF(ticker)\n",
    "\n",
    "        if (init.info['dbtheme']['data']['Asset Class']['text'] != 'Equity') or int(init.info['historical_trade_data']['data']['3 Month Avg. Volume'].replace(',','')) < volume_threshold:\n",
    "            clear_output()\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                holdings_dict[ticker] = scrape_barchart(f'https://www.barchart.com/stocks/quotes/{ticker}/constituents', 'EtfConstituents', bc_params)\n",
    "                all_holdings.extend(holdings_dict[ticker].index.to_list())\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "    all_holdings = [x for x in all_holdings if len(x) > 0]\n",
    "    \n",
    "    return holdings_dict, list(set(all_holdings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_holdings_ivs(all_holdings: list, dte: int=30, strike_count: int=1, use_hist_data: bool=False, iv_df=None):\n",
    "    holdings_iv_dict = {}\n",
    "    if use_hist_data:\n",
    "        all_holdings = [x for x in all_holdings if x in iv_df.columns]\n",
    "        holdings_iv_dict = iv_df.loc[:,all_holdings].iloc[-1,:].to_dict()\n",
    "        return holdings_iv_dict\n",
    " \n",
    "    else:\n",
    "        for holding in tqdm(all_holdings):\n",
    "            print('GETTING IV: '+holding)\n",
    "            try:\n",
    "                holdings_iv_dict[holding] = rv.get_current_iv(holding, dte=dte, strike_count=strike_count)\n",
    "            except KeyError:\n",
    "                holdings_iv_dict[holding] = np.nan\n",
    "            clear_output()\n",
    "        return holdings_iv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_etf_ivs(holdings_dict: dict, dte: int=30, strike_count: int=1, use_hist_data: bool=False, iv_df=None):\n",
    "    etf_iv_dict = {}\n",
    "    \n",
    "    if use_hist_data:\n",
    "        etfs = [x for x in list(holdings_dict.keys()) if x in iv_df.columns]\n",
    "        etf_iv_dict = iv_df.loc[:,etfs].iloc[-1,:].to_dict()\n",
    "    else:\n",
    "        etfs = list(holdings_dict.keys())\n",
    "        for ticker in tqdm(etfs):\n",
    "            print('GETTING IV: '+ticker)\n",
    "            try:\n",
    "                etf_iv_dict[ticker] = rv.get_current_iv(ticker, dte=dte, strike_count=strike_count)\n",
    "            except KeyError:\n",
    "                continue\n",
    "            clear_output()\n",
    "    return etf_iv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_holdings_corrs(stockpx_df: pd.DataFrame, corr_window: int=365):\n",
    "    corrs = stockpx_df.iloc[-corr_window:, :].pct_change().corr()\n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_implied_corrs(holdings_dict: dict, holdings_iv_dict: dict, etf_iv_dict: dict, corr_df: pd.DataFrame, share_threshold: float):\n",
    "    dispersion_dict = {}\n",
    "\n",
    "    for ticker in tqdm(list(holdings_dict.keys())):\n",
    "        if ticker not in list(etf_iv_dict.keys()):\n",
    "            continue\n",
    "        print(f'WORKING: {ticker}')\n",
    "        df = holdings_dict[ticker][(holdings_dict[ticker].index.isin(holdings_iv_dict.keys())) & (holdings_dict[ticker].index != ticker)]\n",
    "        if df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        for h in df.index:\n",
    "            df.loc[h, 'current_iv'] = holdings_iv_dict[h]/100\n",
    "            \n",
    "        \n",
    "        df = df[df['current_iv'] > 0]\n",
    "        df['Share_num'] = pd.to_numeric(df['percent'].str.replace('%',''))/100\n",
    "        total_share_represented = df['Share_num'].sum()\n",
    "        if total_share_represented <= share_threshold:\n",
    "            continue\n",
    "        \n",
    "        etf_iv = etf_iv_dict[ticker]/100\n",
    "        \n",
    "\n",
    "        term1 = ((df['Share_num']**2)*(df['current_iv']**2)).sum()\n",
    "        term2 = 2*(sum([(df.loc[t1, 'Share_num']/total_share_represented)*(df.loc[t2, 'Share_num']/total_share_represented)*df.loc[t1, 'current_iv']*df.loc[t2, 'current_iv'] \n",
    "                                        for t1,t2 in itertools.combinations(df.index,2)]))\n",
    "        term2wcorr = 2*(sum([(df.loc[t1, 'Share_num']/total_share_represented)*(df.loc[t2, 'Share_num']/total_share_represented)*df.loc[t1, 'current_iv']*df.loc[t2, 'current_iv']*corr_df.loc[t1,t2]\n",
    "                                        for t1,t2 in itertools.combinations(df.index,2)]))\n",
    "\n",
    "        etf_implied_corr = (etf_iv**2 - term1) / term2\n",
    "        etf_expected_iv = (term1 + term2wcorr)**0.5\n",
    "        etf_dispersion = ((df['Share_num']/total_share_represented)*(df['current_iv']**2)).sum() - etf_iv**2\n",
    "        \n",
    "        dispersion_dict[ticker] = [total_share_represented*100, etf_implied_corr*100, etf_dispersion, \n",
    "                                   etf_expected_iv*100, etf_iv*100, (etf_iv - etf_expected_iv)*100, list(df.index)]\n",
    "        clear_output()\n",
    "\n",
    "    dispersion_df = pd.DataFrame.from_dict(dispersion_dict, 'index', \n",
    "                                           columns = ['total_share_represented' ,'implied_corr', 'dispersion', 'expected_iv', 'current_iv', 'premium', 'holdings'])\n",
    "\n",
    "    return dispersion_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ivs_and_implied_corrs(yahoo_screen: str, basepath: str, n: int=200, use_hist_data: bool=True, corr_window: int=365, volume_threshold: int=1_000_000, share_threshold: float=0.5, strike_count: int=1):\n",
    "    \n",
    "    dfdict = rv.read_hist_iv_data_from_csv(basepath)\n",
    "    stockpx_df = dfdict['stockpx']\n",
    "    iv30_df = dfdict['iv_30']\n",
    "    iv60_df = dfdict['iv_60']\n",
    "    iv90_df = dfdict['iv_90']\n",
    "    corr_df = get_all_holdings_corrs(stockpx_df=stockpx_df,corr_window=corr_window)\n",
    "\n",
    "    holdings_dict, all_holdings = get_etf_holdings(yahoo_screen, n, volume_threshold=volume_threshold)\n",
    "\n",
    "    holdings_iv_dict_30 = get_all_holdings_ivs(all_holdings, dte=30, strike_count=strike_count, use_hist_data=use_hist_data, iv_df=iv30_df)\n",
    "    holdings_iv_dict_60 = get_all_holdings_ivs(all_holdings, dte=60, strike_count=strike_count, use_hist_data=use_hist_data, iv_df=iv60_df)\n",
    "    holdings_iv_dict_90 = get_all_holdings_ivs(all_holdings, dte=90, strike_count=strike_count, use_hist_data=use_hist_data, iv_df=iv90_df)\n",
    "\n",
    "    etf_iv_dict_30 = get_all_etf_ivs(holdings_iv_dict_30, dte=30, strike_count=strike_count, use_hist_data=use_hist_data, iv_df=iv30_df)\n",
    "    etf_iv_dict_60 = get_all_etf_ivs(holdings_iv_dict_60, dte=60, strike_count=strike_count, use_hist_data=use_hist_data, iv_df=iv60_df)\n",
    "    etf_iv_dict_90 = get_all_etf_ivs(holdings_iv_dict_90, dte=60, strike_count=strike_count, use_hist_data=use_hist_data, iv_df=iv90_df)\n",
    "    \n",
    "    implied_corrs_30 = get_implied_corrs(holdings_dict, holdings_iv_dict_30, etf_iv_dict_30, corr_df, share_threshold=share_threshold)\n",
    "    implied_corrs_60 = get_implied_corrs(holdings_dict, holdings_iv_dict_60, etf_iv_dict_60, corr_df, share_threshold=share_threshold)\n",
    "    implied_corrs_90 = get_implied_corrs(holdings_dict, holdings_iv_dict_90, etf_iv_dict_90, corr_df, share_threshold=share_threshold)\n",
    "\n",
    "    implied_corrs_30.to_csv(f'ETF_Implied_Corrs/implied_corrs_30_{datetime.today().replace(microsecond=0)}.csv')\n",
    "    implied_corrs_60.to_csv(f'ETF_Implied_Corrs/implied_corrs_60_{datetime.today().replace(microsecond=0)}.csv')\n",
    "    implied_corrs_90.to_csv(f'ETF_Implied_Corrs/implied_corrs_90_{datetime.today().replace(microsecond=0)}.csv')\n",
    "\n",
    "    return implied_corrs_30, implied_corrs_60, implied_corrs_90\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
