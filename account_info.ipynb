{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tda\n",
    "from tda.auth import easy_client\n",
    "from tda.client import Client\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import httpx\n",
    "import json\n",
    "from datetime import date, datetime, timedelta\n",
    "import lxml\n",
    "import html5lib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import selenium.common.exceptions\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--start-maximized')\n",
    "chrome_options.page_load_strategy = 'eager'\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('e.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize chromedriver function \n",
    "def driver():\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "#initialize TDA easy_client\n",
    "c = easy_client(\n",
    "    webdriver_func=driver,\n",
    "    api_key=os.environ['tda_api_key'],\n",
    "    redirect_uri='https://localhost',\n",
    "    token_path='token.json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades(account_id='255715792', lookback: int=365, start_date=None, write_to_file: bool=True):    \n",
    "    r = c.get_transactions(account_id=account_id, transaction_type=Client.Transactions.TransactionType('TRADE'))\n",
    "    assert r.status_code == httpx.codes.OK, r.raise_for_status()\n",
    "    txns = pd.read_json(r)[['netAmount', 'transactionDate']]\n",
    "    trades = list(pd.read_json(r)['transactionItem'])\n",
    "    trades = pd.DataFrame(trades)\n",
    "    inst = pd.DataFrame(list(trades['instrument']))\n",
    "    trades[['underlying', 'putCall']] = inst[['underlyingSymbol', 'putCall']]\n",
    "    txns[['amount', 'price', 'cost', 'instruction', 'positionEffect', 'underlying', 'putCall']] = trades[['amount', 'price', 'cost', 'instruction', 'positionEffect', 'underlying', 'putCall']]\n",
    "    txns.set_index('transactionDate', inplace=True)\n",
    "    txns.index = pd.to_datetime(txns.index).tz_localize(None)\n",
    "    if start_date is not None:\n",
    "        trades = txns[txns.index >= start_date]\n",
    "    else:   \n",
    "        trades = txns[txns.index >= datetime.today()-timedelta(lookback)]\n",
    "\n",
    "    trades['date'] = trades.index.date\n",
    "    trades = trades.groupby(by=['underlying', 'positionEffect', 'date'],as_index=False)['cost'].sum()\n",
    "    trades['cost'] = trades['cost']*-1\n",
    "    open = trades[trades['positionEffect']=='OPENING'].set_index('underlying')\n",
    "    clos = trades[trades['positionEffect']=='CLOSING'].set_index('underlying')\n",
    "\n",
    "    trades2 = pd.merge(open, clos, how='outer', left_index=True, right_index=True, suffixes=['_open','_close'])\n",
    "    trades3 = trades2[trades2['date_close'] > trades2['date_open']].reset_index().drop_duplicates(subset=['underlying','date_close'],keep='last')\n",
    "    trades4 = trades3.groupby(['underlying','date_open'])['cost_close'].sum()\n",
    "    trades5 = trades3.groupby(['underlying','date_open'])['date_close'].last()\n",
    "    trades6 = pd.merge(open, trades4, how='left', left_on=['underlying','date'], right_index=True)\n",
    "    trades7 = pd.merge(trades6, trades5, how='left', left_on=['underlying','date'], right_index=True) \\\n",
    "                        .drop('positionEffect',axis=1).rename(columns={'cost': 'cost_open', 'date':'date_open'}) \\\n",
    "                        .reindex(['date_open','cost_open','date_close','cost_close'],axis=1)\n",
    "    trades7['cost_close'] = trades7['cost_close']*-1\n",
    "    \n",
    "    if write_to_file:\n",
    "        if start_date is not None:\n",
    "            trades7.to_csv(f'trades_from_{start_date.date().month}-{start_date.date().day}_{datetime.today().replace(microsecond=0)}.csv')\n",
    "        else:\n",
    "            trades7.to_csv(f'trades_last{lookback}_{datetime.today().replace(microsecond=0)}.csv')\n",
    "    \n",
    "    return trades7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_watchlists(account_id='255715792'):    \n",
    "    p = c.get_watchlists_for_single_account(account_id='255715792')\n",
    "    assert p.status_code == httpx.codes.OK, p.raise_for_status()\n",
    "    wls = pd.read_json(p)\n",
    "    wl_dict = {}\n",
    "    for name in wls['name']:\n",
    "        wl = wls[wls.name == name]\n",
    "        wlsymbols = {str(name): pd.Series([d['symbol'] for d in list(pd.DataFrame(list(wl.loc[:,'watchlistItems'])[0])['instrument'])])}\n",
    "        wl_dict.update(wlsymbols)\n",
    "    \n",
    "    watchlists = pd.DataFrame(wl_dict)\n",
    "    return watchlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txns(account_id='255715792',txn_type='ALL'):\n",
    "    \"\"\" \n",
    "    txn_type = 'ALL' or 'TRADE' or 'BUY_ONLY' or 'SELL_ONLY' or 'CASH_IN_OR_CASH_OUT' or 'CHECKING' or 'DIVIDEND' or 'INTEREST' or 'OTHER' or 'ADVISORY_FEES' \n",
    "    \"\"\"\n",
    "    t = c.get_transactions(account_id=account_id,transaction_type=Client.Transactions.TransactionType(txn_type))\n",
    "    assert t.status_code == httpx.codes.OK, t.raise_for_status()\n",
    "    txns = list(pd.read_json(t)['transactionItem'])\n",
    "    txns = pd.DataFrame(txns)\n",
    "    inst = pd.DataFrame(list(txns['instrument']))\n",
    "    txns = txns.join(inst[['underlying','optionExp','putCall']].reset_index())\n",
    "    txns.join()\n",
    "    return txns, inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades_raw(filename_html):\n",
    "    HTMLFileToBeOpened = open(filename_html, \"r\")\n",
    "    open_pos = pd.read_html(HTMLFileToBeOpened,match='Options')[0][['Symbol','Exp','Strike','Type','Qty']].dropna(subset='Symbol')\n",
    "    HTMLFileToBeOpened = open(filename_html, \"r\")\n",
    "    trades = pd.read_html(HTMLFileToBeOpened,match='Account Trade History')[0].reset_index()\n",
    "    trades['open_pos'] = np.where(pd.merge(trades,open_pos,how='left',on=['Symbol','Exp','Strike','Type','Qty'],indicator='exists').exists == 'both',1,0)\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get PNL info for each strategy in paper trading account using HTML file exported\n",
    "def get_trades_grouped(trades_raw: pd.DataFrame):\n",
    "\n",
    "    trades = trades_raw[trades_raw['open_pos'] != 1]\n",
    "\n",
    "    trades = trades.query('Spread.str.len() > 0 and  Spread != \"STOCK\" and Spread != \"COVERED\"')\n",
    "\n",
    "    #put relevant columns to numeriec\n",
    "    trades[['Qty','Price','Net Price']] = trades[['Qty','Price','Net Price']].apply(pd.to_numeric)\n",
    "\n",
    "    #calculated credits (+ for opening credits, - for closing debits and vice versa)\n",
    "    trades['Credits'] = trades['Qty']*trades['Net Price']*-100\n",
    "\n",
    "    #set trade time to dt\n",
    "    trades['Exec Time'] = pd.to_datetime(trades['Exec Time'])\n",
    "\n",
    "    #order by symbol then trade time\n",
    "    trades.sort_values(['Symbol','Exec Time'], inplace=True)\n",
    "    #trades.reset_index(inplace=True)\n",
    "\n",
    "    #set index\n",
    "\n",
    "    #create trade ID for each symbol/expiration combo (i.e. each spread)\n",
    "    trades['trade_id'] = trades.groupby(['Symbol','Exp']).ngroup() + 1\n",
    "\n",
    "    \n",
    "    trades = trades[trades.groupby('trade_id').trade_id.transform('count')>1]   \n",
    "    \n",
    "\n",
    "    #order trades (opening and closing) for each trade_id\n",
    "    trades['rownum'] = trades.groupby('trade_id')['Exec Time'].rank(method='first')\n",
    "\n",
    "    trades.drop(trades[(trades['rownum'] == 1) & (trades['Pos Effect'] == 'TO CLOSE')].index, inplace=True)\n",
    "\n",
    "    #map spreads to strategy\n",
    "    def strat_map(spread):\n",
    "        if (spread == 'IRON CONDOR') or (spread == 'STRADDLE') or (spread == 'STRANGLE'):\n",
    "            return 'EARNINGS'\n",
    "        elif (spread == 'CALENDAR') or (spread == 'BUTTERFLY'):\n",
    "            return 'FORWARD VOL'\n",
    "        elif (spread == '~BUTTERFLY'):\n",
    "            return 'SKEW'\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "\n",
    "\n",
    "    #apply spread to strategy mapping\n",
    "    trades['Strategy'] = trades['Spread'].apply(strat_map)\n",
    "\n",
    "    #create temp df for opening trades and unknown trades, to fill strategies for unknowns\n",
    "    temp = trades.copy()[(trades['rownum'] == 1) | (trades['Strategy'] == 'UNKNOWN')]\n",
    "\n",
    "    #for opening legs that are unknown, set to FORWARD VOL\n",
    "    #temp['Strategy'] = np.where((temp['Strategy'] == 'UNKNOWN') & (temp['rownum']==1), 'FORWARD VOL', temp['Strategy'])\n",
    "\n",
    "    #replace UNKNOWN with NaN for forward fill\n",
    "    temp['Strategy'].replace('UNKNOWN',np.nan,inplace=True)\n",
    "\n",
    "    #forward fill unknowns (NaNs) from opening trades\n",
    "    temp['Strategy'].fillna(method='ffill',inplace=True)\n",
    "\n",
    "    #merge filled strategies and replace UNKNOWN in original df with them\n",
    "    trades = trades.merge(temp[['Symbol','Exec Time','Strategy']],how='left',on=['Symbol','Exec Time'])\n",
    "    trades['Strategy'] = np.where(trades['Strategy_x'] == 'UNKNOWN', trades['Strategy_y'], trades['Strategy_x'])\n",
    "    trades.drop(['Strategy_x','Strategy_y'],axis=1,inplace=True)\n",
    "\n",
    "    trades_final = trades.copy()\n",
    "\n",
    "    #identify winners and loserse based on sum of credits - put 1/0 on opening trade to keep unique\n",
    "    trades_final['winner'] = np.where((trades_final.groupby('trade_id')['Credits'].transform('sum') > 0) \\\n",
    "                                            & (trades_final['rownum'] == 1), 1, 0)\n",
    "    trades_final['loser'] = np.where((trades_final.groupby('trade_id')['Credits'].transform('sum') <= 0) \\\n",
    "                                            & (trades_final['rownum'] == 1), 1, 0)\n",
    "\n",
    "    #sum winners and losers to get total number of trades\n",
    "    trades_final['num_trades'] = trades_final['winner'] + trades_final['loser'] \n",
    "\n",
    "    #get opening and closing credits separately for each trade to calculate ROC, etc\n",
    "    trades_final['Opening Credits'] = np.where(trades_final['Pos Effect'] == 'TO OPEN', trades_final['Credits'], 0)\n",
    "    trades_final['Closing Credits'] = np.where(trades_final['Pos Effect'] == 'TO CLOSE', trades_final['Credits'], 0)\n",
    "\n",
    "    return trades_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades_wide(trades_grouped: pd.DataFrame):\n",
    "    #pivot table by trade\n",
    "    trades_wide = pd.pivot_table(trades_grouped, values = ['winner','loser','Opening Credits','Closing Credits'], index = ['trade_id'], aggfunc = np.sum).reset_index()\n",
    "    \n",
    "    trades_wide['trade_id'] = np.where((trades_wide['Opening Credits'] == 0) | (trades_wide['Closing Credits'] == 0),trades_wide['trade_id'] + 1, trades_wide['trade_id'])\n",
    "\n",
    "    #trades_wide = pd.pivot_table(trades_wide, values = ['winner','loser','Opening Credits','Closing Credits'], index = ['trade_id'], aggfunc = np.sum).reset_index()\n",
    "    \n",
    "    trades_wide = pd.merge(trades_wide,trades_grouped[['trade_id','Symbol','Strategy']].drop_duplicates(),how='inner',on='trade_id')\n",
    "\n",
    "    \n",
    "\n",
    "    #calculations for each trade\n",
    "    trades_wide['Profit'] = trades_wide['Opening Credits'] + trades_wide['Closing Credits']\n",
    "    trades_wide['roc'] = trades_wide['Profit']/np.abs(trades_wide['Opening Credits'])\n",
    "    trades_wide['Winner Profit'] = trades_wide['winner']*trades_wide['Profit']\n",
    "    trades_wide['Loser Profit'] = trades_wide['loser']*np.abs(trades_wide['Profit'])\n",
    "    \n",
    "\n",
    "    trades_wide = trades_wide.drop_duplicates(subset='trade_id')\n",
    "    return trades_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pnl(trades_wide):\n",
    "    pnl = pd.pivot_table(trades_wide, values = ['Opening Credits','Closing Credits','winner','loser','Profit','Winner Profit','Loser Profit'],index='Strategy',aggfunc=np.sum)\n",
    "\n",
    "    pnl['num_trades'] = pnl['loser'] + pnl['winner']\n",
    "    pnl['Win Rate'] = pnl['winner']/pnl['num_trades']\n",
    "    \n",
    "    pnl['ROC'] = pnl['Profit']/np.abs(pnl['Opening Credits'])\n",
    "\n",
    "    pnl['Avg Capital'] = np.abs(pnl['Opening Credits'])/pnl['num_trades']\n",
    "    pnl['Avg Proft'] = pnl['Profit']/pnl['num_trades']\n",
    "\n",
    "    pnl['Avg Winner'] = pnl['Winner Profit']/pnl['winner']\n",
    "    pnl['Avg Loser'] = pnl['Loser Profit']/pnl['loser']\n",
    "\n",
    "    pnl['Kelly %'] = pnl['Win Rate'] - (1-pnl['Win Rate'])/(pnl['Avg Winner']/pnl['Avg Loser'])\n",
    "\n",
    "    return pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades_by_exp(account_id: str='255715792', lookback: int=365, start_date=None, write_to_file: bool=True, symbols: list=None):\n",
    "    r = c.get_transactions(account_id=account_id, transaction_type=Client.Transactions.TransactionType('TRADE'))\n",
    "    assert r.status_code == httpx.codes.OK, r.raise_for_status()\n",
    "    txns = pd.read_json(r)[['netAmount', 'transactionDate']]\n",
    "    trades = list(pd.read_json(r)['transactionItem'])\n",
    "    trades = pd.DataFrame(trades)\n",
    "\n",
    "    inst = pd.DataFrame(list(trades['instrument']))\n",
    "    trades[['underlying', 'exp', 'putCall', 'cusip']] = inst[['underlyingSymbol', 'optionExpirationDate', 'putCall', 'cusip']]\n",
    "    if symbols is not None:\n",
    "        trades = trades[trades['underlying'].isin(symbols)]\n",
    "\n",
    "    trades['strike'] = pd.to_numeric(trades['cusip'].str[-7:])/1000\n",
    "\n",
    "    txns[['amount', 'price', 'cost', 'instruction', 'positionEffect', 'underlying', 'exp', 'strike', 'putCall']] = \\\n",
    "        trades[['amount', 'price', 'cost', 'instruction', 'positionEffect', 'underlying', 'exp', 'strike', 'putCall']]\n",
    "    \n",
    "    txns.set_index('transactionDate', inplace=True)\n",
    "    txns.index = pd.to_datetime(txns.index).tz_localize(None)\n",
    "    if start_date is not None:\n",
    "        trades = txns[txns.index >= start_date]\n",
    "    else:   \n",
    "        trades = txns[txns.index >= datetime.today()-timedelta(lookback)]\n",
    "\n",
    "    trades['date'] = trades.index.date\n",
    "    trades['exp'] = pd.to_datetime(trades['exp']).dt.date\n",
    "\n",
    "\n",
    "    closing = trades[trades['positionEffect'] == 'CLOSING']\n",
    "    opening = trades[trades['positionEffect'] == 'OPENING']\n",
    "    closing2 = closing.groupby(by=['underlying','exp','strike'])[['amount','cost']].sum()\n",
    "    opening2 = opening.groupby(by=['underlying','exp','strike'])[['amount','cost']].sum()\n",
    "    closing3 = closing.groupby(by=['underlying','exp','strike'])['date'].max()\n",
    "    opening3 = opening.groupby(by=['underlying','exp','strike'])['date'].min()\n",
    "    trades2 = pd.merge(opening2, closing2, how='outer', left_index=True, right_index=True, suffixes=['_open','_close'])\n",
    "    trades2['cost_open'] = trades2['cost_open']*-1\n",
    "\n",
    "    trades2 = pd.merge(trades2, opening3, how='left', left_index=True, right_index=True)\n",
    "    trades2 = pd.merge(trades2, closing3, how='left', left_index=True, right_index=True, suffixes = ['_open','_close'])\n",
    "\n",
    "    trades2['date_close'] = trades2['date_close'].where(trades2['amount_open']==trades2['amount_close'], np.nan)\n",
    "\n",
    "    trades2 = trades2[['date_open', 'amount_open', 'cost_open', 'date_close', 'amount_close', 'cost_close']]\n",
    "    if write_to_file:\n",
    "        if start_date is not None:\n",
    "            trades2.to_csv(f'trades_by_exp_from_{start_date.date().month}-{start_date.date().day}_{datetime.today().replace(microsecond=0)}.csv')\n",
    "        else:\n",
    "            trades2.to_csv(f'trades_by_exp_last{lookback}_{datetime.today().replace(microsecond=0)}.csv')\n",
    "\n",
    "    return trades2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_positions(account_id='255715792', write_to_file: bool=False, symbols: list=None):\n",
    "    open_pos = c.get_account(account_id = account_id, fields=Client.Account.Fields('positions'))\n",
    "    res = pd.DataFrame(pd.read_json(open_pos).T['positions'].values[0])\n",
    "    inst = pd.DataFrame(res['instrument'].to_list())\n",
    "    res = res[['shortQuantity','longQuantity','marketValue','maintenanceRequirement']]\n",
    "    res['quantity'] = res['longQuantity'] - res['shortQuantity']\n",
    "    res[['symbol','cusip', 'putCall','underlying']] = inst[['symbol','cusip','putCall','underlyingSymbol']]\n",
    "    res['strike'] = pd.to_numeric(res['cusip'].str[-7:])/1000\n",
    "\n",
    "    res = res.drop(['shortQuantity', 'longQuantity', 'cusip'], axis=1).set_index('symbol').sort_index()\n",
    "    \n",
    "    if symbols is not None:\n",
    "        res = res[res['underlying'].isin(symbols)]\n",
    "\n",
    "    if write_to_file:\n",
    "        res.to_csv(f'open_positions_{datetime.today().replace(microsecond=0)}.csv')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spread_trades(filename_html: str, symbols: list or str = None, spread_types: list or str = None, write_to_file: bool=False):\n",
    "\n",
    "    x = get_trades_raw(filename_html)\n",
    "\n",
    "    x['Exec Time'] = pd.to_datetime(x['Exec Time'], format='%m/%d/%y %H:%M:%S')\n",
    "\n",
    "    x2 = x[x['Symbol'].isin(symbols)].drop(['Unnamed: 0','index'], axis=1)\n",
    "\n",
    "    x2 = x2.fillna(method='ffill').replace('DEBIT',np.nan).replace('CREDIT', np.nan).sort_values(by='Exec Time', ascending=False)\n",
    "\n",
    "    x3 = x2.copy()\n",
    "\n",
    "    x3['Net Price'] = pd.to_numeric(x3['Net Price'])\n",
    "\n",
    "    x3['Main Strike'] = np.where(((x3['Spread'] == 'BUTTERFLY') & (x3['Qty'] > 0)) | ((x3['Spread'] == 'VERTICAL') & (x3['Qty'] < 0)), np.nan, x3['Strike'])\n",
    "\n",
    "    x3['Main Qty'] = np.where(((x3['Spread'] == 'BUTTERFLY') | (x3['Spread'] == 'VERTICAL')) & (np.isnan(x3['Net Price'])), np.nan, x3['Qty'])\n",
    "\n",
    "    x3['Cost'] = x3['Net Price']*x3['Main Qty']*100\n",
    "        \n",
    "    closes2 = x3[x3['Pos Effect']=='TO CLOSE']\n",
    "\n",
    "    opens2 = x3[x3['Pos Effect']=='TO OPEN']\n",
    "\n",
    "    opens3 = opens2.groupby(['Symbol', 'Spread', 'Exp', 'Strike']).agg(exec_time = ('Exec Time', min), qty = ('Qty', sum), cost = ('Cost', sum), \n",
    "                                                                    main_strike = ('Main Strike', max), main_qty = ('Main Qty', sum))\n",
    "\n",
    "    closes3 = closes2.reset_index().set_index(['Symbol', 'Exp', 'Strike']).rename(columns={'Exec Time': 'exec_time', 'Qty': 'qty', 'Main Strike': 'main_strike',\n",
    "                                                                                        'Main Qty': 'main_qty', 'Cost': 'cost'}) \\\n",
    "                                                                                            .drop(['Side', 'Pos Effect', 'Price', 'Net Price', 'Order Type', 'open_pos', 'index'], axis=1)\n",
    "\n",
    "    opens3 = opens3.reset_index().set_index(['Symbol', 'Exp', 'Strike'])\n",
    "\n",
    "    trades = pd.merge(opens3, closes3, how='outer', left_index=True, right_index=True, suffixes=['_open','_close']).reset_index()\n",
    "\n",
    "    trades['exec_time_close'] = trades['exec_time_close'].where( (trades['exec_time_close'] > trades['exec_time_open']) | (trades['exec_time_close'].isna()), np.nan)\n",
    "\n",
    "    trades['qty_close'] = trades['qty_close'].where((np.sign(trades['qty_close']) != np.sign(trades['qty_open'])) & \n",
    "                                                    (~trades['qty_close'].isna()) & \n",
    "                                                    (np.abs(trades['qty_close']) <= np.abs(trades['qty_open'])) &\n",
    "                                                    (~trades['exec_time_close'].isna()), np.nan)\n",
    "\n",
    "    trades[['Spread_close', 'Type', 'main_strike_close', 'main_qty_close', 'cost_close']] = \\\n",
    "        trades[['Spread_close', 'Type', 'main_strike_close', 'main_qty_close', 'cost_close']].where((~trades['exec_time_close'].isna()) &\n",
    "                                                                                                                        (~trades['qty_close'].isna()), np.nan)\n",
    "\n",
    "    trades = trades.drop_duplicates()\n",
    "\n",
    "    trades['main_strike_open'] = trades['main_strike_open'].where(~trades['main_strike_open'].isna(), 0)\n",
    "\n",
    "    trades2 = trades.groupby(['Symbol', 'Exp', 'Strike', 'Spread_open', 'exec_time_open', 'qty_open', 'cost_open', 'main_strike_open', 'main_qty_open']) \\\n",
    "                        .agg(exec_time_close = ('exec_time_close', np.nanmax), qty_close = ('qty_close', np.nansum), cost_close = ('cost_close', np.nansum)) \\\n",
    "                        .reset_index()\n",
    "\n",
    "    trades2['qty_close'] = trades2['qty_close'].where(trades2['main_qty_open'] > 0, 0)\n",
    "\n",
    "    trades2 = trades2.sort_values(by=['exec_time_open', 'Strike'], ascending=False)\n",
    "\n",
    "\n",
    "    trades2['capital'] = np.where((trades2['Spread_open'] == 'BUTTERFLY') & (trades2['cost_open'] < 0), \n",
    "                            ((trades2['Strike'] - trades2['Strike'].shift(-1))*100*trades2['main_qty_open'] + trades2['cost_open']),\n",
    "                            trades2['cost_open'])\n",
    "\n",
    "    trades3 = trades2[trades2['Spread_open'] != 'SINGLE']\n",
    "\n",
    "    trades4 = trades3.groupby(['Symbol', 'Exp', 'Spread_open', 'exec_time_open']).agg(main_strike = ('main_strike_open', np.nansum), qty_open = ('main_qty_open', np.nansum), \n",
    "                                                                                        cost_open = ('cost_open', np.nansum), cap_at_risk = ('capital', np.nansum),\n",
    "                                                                                        exec_time_close = ('exec_time_close', np.nanmax), qty_close = ('qty_close', np.nansum), \n",
    "                                                                                        cost_close = ('cost_close', np.nansum)).reset_index()\n",
    "\n",
    "    singles = trades2[trades2['Spread_open'] == 'SINGLE'][['Symbol', 'Exp', 'Spread_open', 'main_strike_open', 'exec_time_open', 'main_qty_open', 'cost_open', 'capital',\n",
    "                                                        'exec_time_close', 'qty_close', 'cost_close']].rename(columns={'main_strike_open': 'main_strike',\n",
    "                                                                                                        'main_qty_open': 'qty_open',\n",
    "                                                                                                        'capital': 'cap_at_risk',\n",
    "                                                                                                        'qty_close': 'qty_close'})\n",
    "\n",
    "    trades5 = pd.concat([trades4, singles]).sort_values(by='exec_time_open', ascending=False)\n",
    "\n",
    "    trades5['exec_time_open'] = trades5['exec_time_open'].dt.date\n",
    "\n",
    "    trades5['exec_time_close'] = trades5['exec_time_close'].dt.date\n",
    "\n",
    "    trades5['cost_close'] = trades5['cost_close']*-1\n",
    "\n",
    "    trades5 = trades5.rename(columns={'Symbol': 'underlying', 'Exp': 'exp', 'Spread_open': 'spread', 'main_strike': 'strike', 'exec_time_open': 'date_open', 'exec_time_close': 'date_close'}).set_index('underlying')\n",
    "\n",
    "    if 'BUTTERFLY' in spread_types:\n",
    "        trades5 = trades5[['spread', 'exp', 'strike', 'date_open', 'qty_open', 'cost_open', 'cap_at_risk', 'date_close', 'qty_close', 'cost_close']]\n",
    "    else:\n",
    "        trades5 = trades5[['spread', 'exp', 'strike', 'date_open', 'qty_open', 'cost_open', 'date_close', 'qty_close', 'cost_close']]\n",
    "\n",
    "    if spread_types is not None:\n",
    "        trades5 = trades5[trades5['spread'].isin(spread_types)]\n",
    "\n",
    "    if write_to_file:\n",
    "        trades5.to_csv(f'spread_trades_{datetime.today().replace(microsecond=0)}.csv')\n",
    "\n",
    "    return trades5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>exp</th>\n",
       "      <th>strike</th>\n",
       "      <th>date_open</th>\n",
       "      <th>qty_open</th>\n",
       "      <th>cost_open</th>\n",
       "      <th>date_close</th>\n",
       "      <th>qty_close</th>\n",
       "      <th>cost_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underlying</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>VERTICAL</td>\n",
       "      <td>17 NOV 23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-08-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>VERTICAL</td>\n",
       "      <td>18 AUG 23</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2023-08-14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>VERTICAL</td>\n",
       "      <td>17 NOV 23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2023-08-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>VERTICAL</td>\n",
       "      <td>29 SEP 23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-08-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>VERTICAL</td>\n",
       "      <td>15 SEP 23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2023-08-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>SINGLE</td>\n",
       "      <td>16 JUN 23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>9.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>SINGLE</td>\n",
       "      <td>9 JUN 23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>SINGLE</td>\n",
       "      <td>2 JUN 23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>SINGLE</td>\n",
       "      <td>26 MAY 23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVXY</th>\n",
       "      <td>SINGLE</td>\n",
       "      <td>19 MAY 23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              spread        exp  strike   date_open  qty_open  cost_open  \\\n",
       "underlying                                                                 \n",
       "UVXY        VERTICAL  17 NOV 23    16.0  2023-08-14       3.0      564.0   \n",
       "UVXY        VERTICAL  18 AUG 23    17.5  2023-08-14       7.0      371.0   \n",
       "UVXY        VERTICAL  17 NOV 23    17.0  2023-08-10       3.0      585.0   \n",
       "UVXY        VERTICAL  29 SEP 23    16.0  2023-08-10       2.0      306.0   \n",
       "UVXY        VERTICAL  15 SEP 23    17.0  2023-08-10       2.0      246.0   \n",
       "...              ...        ...     ...         ...       ...        ...   \n",
       "UVXY          SINGLE  16 JUN 23     3.0  2023-05-31       9.0      322.0   \n",
       "UVXY          SINGLE   9 JUN 23     3.5  2023-05-24       2.0       74.0   \n",
       "UVXY          SINGLE   2 JUN 23     3.5  2023-05-16       7.0      265.0   \n",
       "UVXY          SINGLE  26 MAY 23     3.5  2023-05-15       6.0      174.0   \n",
       "UVXY          SINGLE  19 MAY 23     3.5  2023-05-03      15.0      266.0   \n",
       "\n",
       "            date_close  qty_close  cost_close  \n",
       "underlying                                     \n",
       "UVXY               NaN        0.0        -0.0  \n",
       "UVXY               NaN        0.0        -0.0  \n",
       "UVXY               NaN        0.0        -0.0  \n",
       "UVXY               NaN        0.0        -0.0  \n",
       "UVXY               NaN        0.0        -0.0  \n",
       "...                ...        ...         ...  \n",
       "UVXY        2023-06-06       -9.0       446.0  \n",
       "UVXY        2023-05-26       -2.0       104.0  \n",
       "UVXY        2023-05-26       -7.0       325.0  \n",
       "UVXY        2023-05-26       -5.0       168.0  \n",
       "UVXY        2023-05-12      -15.0       284.0  \n",
       "\n",
       "[83 rows x 9 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spread_trades('2023-08-14-AccountStatement.html', symbols = ['UVXY', 'VXX'], spread_types=['SINGLE','VERTICAL'], write_to_file=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
