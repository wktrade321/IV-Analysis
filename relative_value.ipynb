{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import yfinance as yf\n",
    "from IPython.display import clear_output, display\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import investpy\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import nasdaqdatalink as ndl\n",
    "\n",
    "#TD Ameritrade API for historical equity prices and current quotes\n",
    "from tda.auth import easy_client\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import selenium.common.exceptions\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--start-maximized')\n",
    "chrome_options.page_load_strategy = 'eager'\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv('e.env')\n",
    "\n",
    "\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize chromedriver function \n",
    "def driver():\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "#initialize TDA easy_client\n",
    "c = easy_client(\n",
    "    webdriver_func=driver,\n",
    "    api_key=os.environ['tda_api_key'],\n",
    "    redirect_uri='https://localhost',\n",
    "    token_path='token.json'\n",
    ")\n",
    "\n",
    "\n",
    "ndl.ApiConfig.api_key = os.environ['ndl_api_key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_vix_metrics(return_vals: bool=False, display_vals: bool=True):\n",
    "    text_labels = ['m1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'vix', 'vix3m', 'vix9d', 'vix6m', 'vixmo', 'hv10', 'hv20', 'hv30']\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get('http://vixcentral.com')\n",
    "    soup = BeautifulSoup(driver.page_source, features='lxml').find_all('tspan', {'class': 'highcharts-text-outline'})\n",
    "    values = [float(x.text[:5]) for x in soup]\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "    term_struct = pd.Series(values[:len(text_labels)], index=text_labels)\n",
    "\n",
    "    thirdfris = pd.date_range(datetime.today() - timedelta(30), datetime.today() + timedelta(365),freq='WOM-3FRI')\n",
    "    exps = thirdfris - timedelta(30)\n",
    "\n",
    "    trading_dtes_before = [np.busday_count(datetime.today().date(), exp.date()) for exp in exps if exp < datetime.today()]\n",
    "    trading_dtes_after = [np.busday_count(datetime.today().date(), exp.date()) for exp in exps if exp > datetime.today()]\n",
    "\n",
    "    days_in_cycle = trading_dtes_after[0] - trading_dtes_before[-1]\n",
    "    dte1 = trading_dtes_after[0]\n",
    "    dte2 = trading_dtes_after[1]\n",
    "\n",
    "    roll = 1/days_in_cycle\n",
    "\n",
    "    vx30 = pd.Series(round((term_struct['m1']*dte1*roll) + (term_struct['m2']*(1 - dte1*roll)),2), index=['vx30'])\n",
    "    vx60 = pd.Series(round(term_struct['m3'] - (term_struct['m3'] - term_struct['m2'])*dte2*roll, 2), index=['vx60'])\n",
    "    voli = pd.Series(round(yf.download('^VOLI', progress=False)['Adj Close'].values[0],2), index=['voli'])\n",
    "\n",
    "    term_struct = pd.concat([voli, vx30, vx60, term_struct]) \n",
    "\n",
    "    ratios = pd.Series()\n",
    "\n",
    "    ratios['VX30:VIX'] = round(term_struct['vx30']/term_struct['vix'], 3)\n",
    "    ratios['VIX:VIX9D'] = round(term_struct['vix']/term_struct['vix9d'], 3)\n",
    "    ratios['VIX3M:VIX'] = round(term_struct['vix3m']/term_struct['vix'], 3)\n",
    "    ratios['VIX6M:VIX'] = round(term_struct['vix6m']/term_struct['vix'], 3)\n",
    "    ratios['VX60:VX30'] = round(term_struct['vx60']/term_struct['vx30'], 3)\n",
    "    ratios['M7:M4'] = round(term_struct['m7']/term_struct['m4'], 3)\n",
    "    ratios['VIX:VOLI'] = round(term_struct['vix']/term_struct['voli'], 3)\n",
    "    ratios['VX30:HV30'] = round(term_struct['vx30']/term_struct['hv30'], 3)\n",
    "\n",
    "    \n",
    "    vix9d_hist = yf.download('^VIX9D', progress=False)['Adj Close']\n",
    "    vix_hist = yf.download('^VIX', progress=False)['Adj Close']\n",
    "    vix3m_hist = yf.download('^VIX3M', progress=False)['Adj Close']\n",
    "    vix6m_hist = yf.download('^VIX6M', progress=False)['Adj Close']\n",
    "\n",
    "    vix_vix9d_hist = (vix_hist/vix9d_hist).dropna()\n",
    "    vix3m_vix_hist = (vix3m_hist/vix_hist).dropna()\n",
    "    vix6m_vix_hist = (vix6m_hist/vix_hist).dropna()\n",
    "\n",
    "    percentiles = pd.Series()\n",
    "\n",
    "    percentiles['VIX:VIX9D'] = round(stats.percentileofscore(vix_vix9d_hist.values, ratios['VIX:VIX9D']),2)\n",
    "    percentiles['VIX3M:VIX'] = round(stats.percentileofscore(vix_vix9d_hist.values, ratios['VIX3M:VIX']),2)\n",
    "    percentiles['VIX6M:VIX'] = round(stats.percentileofscore(vix_vix9d_hist.values, ratios['VIX6M:VIX']),2)\n",
    "\n",
    "    if display_vals:\n",
    "        display(pd.DataFrame(ratios, columns=['Ratios:']).T)\n",
    "        display(pd.DataFrame(term_struct, columns=['Term Structure: ']).T)\n",
    "        display(pd.DataFrame(percentiles, columns=['Percentiles: ']).T)\n",
    "\n",
    "\n",
    "    futures_curve = pd.concat([ pd.DataFrame(term_struct['vix'], index=[datetime.today().date()], columns=['VIX Futures']),\n",
    "                              pd.DataFrame(term_struct['m1':'m8'].values, index = [exp.date() for exp in exps if exp > datetime.today()][:8], columns=['VIX Futures']) ])\n",
    "    futures_curve['month'] = ['VIX Spot', 'M1','M2','M3','M4','M5','M6','M7','M8']\n",
    "\n",
    "    futures_curve['VIX Futures'] = pd.to_numeric(futures_curve['VIX Futures'])\n",
    "\n",
    "\n",
    "    if return_vals:\n",
    "        return ratios, term_struct, percentiles, futures_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vix_futures_curve(futures_curve: pd.DataFrame, title: str='vix_futures_curve'):\n",
    "    fig = px.line(data_frame=futures_curve.reset_index(), x='index', y='VIX Futures', markers=True, text='VIX Futures', hover_name='month', hover_data={'index':False, 'month':True, 'VIX Futures': ':.2f'})\n",
    "    fig.update_traces(textposition='top left',texttemplate='%{y:.2f}', hovertemplate=None)\n",
    "    fig.update_layout(hovermode='x unified', plot_bgcolor=\"#333\")\n",
    "    fig.update_xaxes(title_text = 'Expiration')\n",
    "    fig.update_yaxes(title_text = 'VIX Futures')\n",
    "    fig.show()\n",
    "    fig.write_html(f'{title}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_vix_contango(start_date: datetime, end_date: datetime, write_to_file: bool = True, output_path: str='VIX_Contango'):\n",
    "    \n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--start-maximized')\n",
    "    chrome_options.page_load_strategy = 'normal'\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get('http://vixcentral.com')\n",
    "\n",
    "    hist_prices_button = driver.find_element(by=By.XPATH, value='//*[@id=\"ui-id-9\"]')\n",
    "    hist_prices_button.click()\n",
    "\n",
    "    start_date_str = start_date.strftime('%B %d, %Y')\n",
    "\n",
    "\n",
    "    input = driver.find_element(by=By.XPATH, value='//*[@id=\"date1\"]')\n",
    "    input.clear()\n",
    "    input.send_keys(start_date_str)\n",
    "    button = driver.find_element(by=By.XPATH, value='//*[@id=\"b4\"]')\n",
    "    button.click()\n",
    "\n",
    "    current_date = start_date\n",
    "    datadict = {}\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        print(current_date)\n",
    "\n",
    "        if current_date.date() >= datetime.today().date() - timedelta(1):\n",
    "            break\n",
    "        table = BeautifulSoup(driver.page_source, features='lxml').find_all('table')[2]\n",
    "        data = [x.text for x in table.find_all('td')]\n",
    "        datadict[current_date] = data[:7]\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, features='lxml').find_all('tspan', {'class': 'highcharts-text-outline'})\n",
    "        text = [x.text[:5] for x in soup]\n",
    "        m1 = float(text[16])\n",
    "\n",
    "        datadict[current_date].append(m1)\n",
    "\n",
    "        nextbutton = driver.find_element(By.XPATH, '//*[@id=\"bnext\"]')\n",
    "        nextbutton.click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        current_date_str = WebDriverWait(driver,1).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"date1\"]'))).get_property('value')\n",
    "        current_date = datetime.strptime(current_date_str, '%B %d, %Y')\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "    driver.close()\n",
    "    df = pd.DataFrame.from_dict(datadict,'index')\n",
    "    df = df.rename(columns={0:'1-2', 1:'2-3', 2:'3-4', 3:'4-5', 4:'5-6', 5:'6-7', 6:'7-8', 7:'M1'})\n",
    "\n",
    "    vixspot = yf.download('^VIX', start_date, end_date, interval='1d')['Close']\n",
    "\n",
    "    df = df.join(vixspot,how='left')\n",
    "\n",
    "    df['roll_yield'] = df['M1']/df['Close'] - 1\n",
    "\n",
    "    df = df.rename(columns={'Close': 'VIX_spot'})\n",
    "    \n",
    "    if write_to_file:\n",
    "        df.to_csv(f'{output_path}/vix_contango_{start_date.year}-{start_date.month}-{start_date.day}_{end_date.year}-{end_date.month}-{end_date.day}')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "ERR#0015: error 403, try again later.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/wiltonwking/IV Analysis/relative_value.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wiltonwking/IV%20Analysis/relative_value.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m investpy\u001b[39m.\u001b[39;49mget_stock_historical_data(\u001b[39m'\u001b[39;49m\u001b[39mAAPL\u001b[39;49m\u001b[39m'\u001b[39;49m, country\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUnited States\u001b[39;49m\u001b[39m'\u001b[39;49m, from_date\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m01/01/2023\u001b[39;49m\u001b[39m'\u001b[39;49m, to_date\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m27/09/2023\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/investpy/stocks.py:664\u001b[0m, in \u001b[0;36mget_stock_historical_data\u001b[0;34m(stock, country, from_date, to_date, as_json, order, interval)\u001b[0m\n\u001b[1;32m    661\u001b[0m req \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(url, headers\u001b[39m=\u001b[39mhead, data\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    663\u001b[0m \u001b[39mif\u001b[39;00m req\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\n\u001b[1;32m    665\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mERR#0015: error \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(req\u001b[39m.\u001b[39mstatus_code) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, try again later.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m     )\n\u001b[1;32m    668\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m req\u001b[39m.\u001b[39mtext:\n\u001b[1;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ERR#0015: error 403, try again later."
     ]
    }
   ],
   "source": [
    "investpy.get_stock_historical_data('AAPL', country='United States', from_date='01/01/2023', to_date='27/09/2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iv_from_straddle(straddle_price: float, underlying_price: float, dte: int or float=30):\n",
    "    \"\"\"\n",
    "    #IV from straddle price - to be used when current IV data isn't avail\n",
    "    \"\"\"\n",
    "    res = (125*straddle_price)/(underlying_price*np.sqrt(dte/360))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_iv(symbol: str, dte: int=30, strike_count: int=2, volume_lookback: int=1, dte_threshold: int=20):\n",
    "    \"\"\"\n",
    "        get the current ATM implied volatility for a symbol and target DTE from yfinance. \n",
    "\n",
    "        :param dte: the target DTE of the options. The closest standard (monthly) expiration date to today+DTE is used\n",
    "        :param strike_count: how many of the closest ATM strikes are considered in the calc.\n",
    "        :param volume_lookback: number of trading days to look back for traded volume in the strikes being analyzed.\n",
    "                                if any of the strikes have no volume in the period, NaN is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    td = (datetime.today() - BDay(volume_lookback)).date()\n",
    "\n",
    "    try:\n",
    "        tk = yf.Ticker(symbol)\n",
    "    except KeyError:\n",
    "        time.sleep(2)\n",
    "        tk = yf.Ticker(symbol)\n",
    "\n",
    "    try:\n",
    "        s = tk.info['currentPrice']\n",
    "    except KeyError:\n",
    "        s = tk.get_fast_info['lastPrice']\n",
    "\n",
    "    thirdfris = pd.date_range(td,td+timedelta(365),freq='WOM-3FRI')\n",
    "\n",
    "    if len(tk.options) > 0:\n",
    "        ds = [d for d in tk.options if d in thirdfris]\n",
    "        e = ds[pd.Series(abs((pd.to_datetime(ds) - datetime.today()).days - dte)).idxmin()]\n",
    "        if abs((pd.to_datetime(e) - datetime.today()).days - dte) > dte_threshold:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "    try: \n",
    "        calls = pd.DataFrame(tk.option_chain(e).calls)\n",
    "        puts = pd.DataFrame(tk.option_chain(e).puts)\n",
    "    except TypeError:\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            calls = pd.DataFrame(tk.option_chain(e).calls)\n",
    "            puts = pd.DataFrame(tk.option_chain(e).puts)\n",
    "        except TypeError:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "\n",
    "    calls2 = calls[calls['strike'] >= s].sort_values(by='strike', key = lambda x: abs(x-s)).iloc[:strike_count,:]\n",
    "    puts2 = puts[puts['strike'] >= s].sort_values(by='strike', key = lambda x: abs(x-s)).iloc[:strike_count,:]\n",
    "\n",
    "\n",
    "    if (calls2['lastTradeDate'].dt.date < td).any() or (puts2['lastTradeDate'].dt.date < td).any():\n",
    "        return np.nan\n",
    "\n",
    "    opts = pd.concat([calls2, puts2])\n",
    "\n",
    "    if datetime.today().hour >= 10:\n",
    "        return opts['impliedVolatility'].mean()\n",
    "    else: \n",
    "        straddle_price = opts['lastPrice'].mean()*2\n",
    "        dte_exact = (datetime.strptime(e,'%Y-%m-%d') - datetime.today()).days\n",
    "        return get_iv_from_straddle(straddle_price=straddle_price, underlying_price=s, dte=dte_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_iv_data(tickers_avail: list, start_date: datetime or datetime.date=datetime.today()-timedelta(365), end_date: datetime or datetime.date=datetime.today(),\n",
    "                rows: int=None, write_to_file: bool=False):\n",
    "    \"\"\" \n",
    "    pull historical daily IV data from the nasdaq data link series OPT for the provided list of tickers_avail. \n",
    "    If 'rows' is specified, pulls the last <rows> data points.\n",
    "    If not, then pulls data from <start_date> to <end_date>\n",
    "    \"\"\"\n",
    "    iv_dict = {}\n",
    "    if rows is None:\n",
    "        for ticker in tqdm(tickers_avail):\n",
    "            print(ticker)\n",
    "            iv_dict[ticker] = ndl.get(f'OPT/{ticker}', start_date=start_date, end_date=end_date)[['stockpx','iv30','iv60','iv90']]\n",
    "            clear_output()\n",
    "    else:\n",
    "        for ticker in tqdm(tickers_avail):\n",
    "            print(ticker)\n",
    "            iv_dict[ticker] = ndl.get(f'OPT/{ticker}', rows=rows)[['stockpx','iv30','iv60','iv90']]\n",
    "            clear_output()\n",
    "        \n",
    "    stockpx_df = pd.concat([iv_dict[ticker]['stockpx'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "    iv30_df = pd.concat([iv_dict[ticker]['iv30'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "    iv60_df = pd.concat([iv_dict[ticker]['iv60'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "    iv90_df = pd.concat([iv_dict[ticker]['iv90'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "\n",
    "    if write_to_file:\n",
    "        path = f'IV_Data_{datetime.today().date()}'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        stockpx_df.to_csv(path+'/stockpx.csv')\n",
    "        iv30_df.to_csv(path+'/iv_30.csv')\n",
    "        iv60_df.to_csv(path+'/iv_60.csv')\n",
    "        iv90_df.to_csv(path+'/iv_90.csv')\n",
    "    return stockpx_df, iv30_df, iv60_df, iv90_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rvs(stockpx_df: pd.DataFrame, dte: int=30):\n",
    "    df = np.log(stockpx_df/stockpx_df.shift(1))\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.rolling(window=dte).std(ddof=0)*np.sqrt(252)*100\n",
    "    return df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vrps(stockpx_df: pd.DataFrame, iv_df: pd.DataFrame, dte: int=30):\n",
    "    rv_df = get_rvs(stockpx_df=stockpx_df, dte=dte)\n",
    "    vrp_df = (iv_df/rv_df).round(2)\n",
    "    return vrp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_ivs(iv_df, stockpx_df, corr_threshold: float, stockpx_threshold: float=2.0, use_iv_df: bool=False, use_stockpx_corr: bool=False, tickers=None):\n",
    "    tickers = [x for x in tickers if x in iv_df.columns]\n",
    "    iv_df = iv_df.loc[:,tickers]\n",
    "\n",
    "    \n",
    "    if use_iv_df:\n",
    "        iv_df = iv_df.iloc[:-1,:]\n",
    "\n",
    "\n",
    "    if use_stockpx_corr:\n",
    "        tickers = [x for x in tickers if x in stockpx_df.columns]    \n",
    "        stockpx_df = stockpx_df.loc[:,tickers]\n",
    "        corrs = stockpx_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r(S)')\n",
    "    else:\n",
    "        corrs = iv_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r')\n",
    "        \n",
    "    highcorrs = corrs[(corrs<1) & (corrs>corr_threshold)]\n",
    "    highcorrs.index.names = ['pair1', 'pair2']\n",
    "\n",
    "    highcorrs = pd.DataFrame(highcorrs)\n",
    "\n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair1').rename(columns={'0': 'stockpx_1'})\n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair2').rename(columns={'0': 'stockpx_2'})\n",
    "\n",
    "    highcorrs = highcorrs[(highcorrs['stockpx_1'] > stockpx_threshold) & (highcorrs['stockpx_2'] > stockpx_threshold)]\n",
    "\n",
    "    IV_ratios = pd.DataFrame({pair: iv_df[pair[0]]/iv_df[pair[1]] for pair in highcorrs.index})\n",
    "    \n",
    "    return highcorrs, IV_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_vrps(vrp_df, stockpx_df, corr_threshold: float, stockpx_threshold: float=2.0, \n",
    "                        use_vrp_df: bool=False, use_stockpx_corr: bool=False, tickers=None):\n",
    "    tickers = [x for x in tickers if x in vrp_df.columns]\n",
    "    vrp_df = vrp_df.loc[:,tickers]\n",
    "\n",
    "    \n",
    "    if use_vrp_df:\n",
    "        vrp_df = vrp_df.iloc[:-1,:]\n",
    "\n",
    "\n",
    "    if use_stockpx_corr:\n",
    "        tickers = [x for x in tickers if x in stockpx_df.columns]    \n",
    "        stockpx_df = stockpx_df.loc[:,tickers]\n",
    "        corrs = stockpx_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r(S)')\n",
    "    else:\n",
    "        corrs = vrp_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r(VRP)')\n",
    "    highcorrs = corrs[(corrs<1) & (corrs>corr_threshold)]\n",
    "    highcorrs.index.names = ['pair1', 'pair2']\n",
    "\n",
    "    highcorrs = pd.DataFrame(highcorrs)\n",
    "   \n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair1').rename(columns={'0': 'stockpx_1'})\n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair2').rename(columns={'0': 'stockpx_2'})\n",
    "\n",
    "    highcorrs = highcorrs[(highcorrs['stockpx_1'] > stockpx_threshold) & (highcorrs['stockpx_2'] > stockpx_threshold)]\n",
    "\n",
    "    VRP_ratios = pd.DataFrame({pair: vrp_df[pair[0]]/vrp_df[pair[1]] for pair in highcorrs.index})\n",
    "    \n",
    "    return highcorrs, VRP_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_iv_ratio_ranks(iv_ratio_df: pd.DataFrame, corr_df:pd.DataFrame, stockpx_df: pd.DataFrame,\n",
    "                         dte: int=30, strike_count: int=2, volume_lookback: int=1, dte_threshold: int=20, \n",
    "                         exclude_earnings: bool=False, z_window: int=100, use_iv_df: bool=False, iv_df=None):\n",
    "\n",
    "\n",
    "\n",
    "    tickers = np.unique(np.append(iv_ratio_df.columns.to_frame()[0].values, iv_ratio_df.columns.to_frame()[1].values))\n",
    "    current_iv_dict = {}\n",
    "    \n",
    "    if use_iv_df:\n",
    "        current_iv_dict = iv_df.iloc[-1,:].T.to_dict()\n",
    "    else:\n",
    "        for ticker in tqdm(tickers):\n",
    "            print(ticker)\n",
    "            current_iv_dict[ticker] = get_current_iv(ticker, dte=dte, strike_count=strike_count, volume_lookback=volume_lookback, dte_threshold=dte_threshold)\n",
    "            clear_output()\n",
    "\n",
    "\n",
    "    ratio_dict = {}\n",
    "    zscore_dict = {}\n",
    "    pctl_dict = {}\n",
    "    beta_dict = {}\n",
    "    beta_premium_dict = {}\n",
    "    for pair in iv_ratio_df.columns:\n",
    "        ratio_dict[pair] = current_iv_dict[pair[0]]/current_iv_dict[pair[1]]\n",
    "        zscore_dict[pair] = (ratio_dict[pair] - iv_ratio_df[pair][-z_window:].mean())/(iv_ratio_df[pair][-z_window:].std())\n",
    "        pctl_dict[pair] = scipy.stats.percentileofscore(iv_ratio_df[pair][~np.isnan(iv_ratio_df[pair])], \n",
    "                                                                        ratio_dict[pair], 'weak')\n",
    "        beta_dict[pair] = (abs(stockpx_df[pair[0]].pct_change()/stockpx_df[pair[1]].pct_change())).replace([np.inf,-np.inf], np.nan).mean()\n",
    "        beta_premium_dict[pair] = abs(current_iv_dict[pair[1]] - current_iv_dict[pair[0]]*beta_dict[pair])\n",
    "\n",
    "\n",
    "    current_ratio_df = pd.DataFrame.from_dict(ratio_dict, 'index', columns=['iv_ratio'])\n",
    "    zscore_df = pd.DataFrame.from_dict(zscore_dict, 'index', columns=['zscore'])\n",
    "    pctl_df = pd.DataFrame.from_dict(pctl_dict, 'index', columns=['pctl'])\n",
    "    if stockpx_df is not None:\n",
    "        beta_df = pd.DataFrame.from_dict(beta_dict, 'index', columns=['beta'])\n",
    "        beta_premium_df = pd.DataFrame.from_dict(beta_premium_dict, 'index', columns=['beta_premium'])\n",
    "\n",
    "    if stockpx_df is not None:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df, beta_df, beta_premium_df], axis=1, join='inner')\n",
    "    else:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df], axis=1, join='inner')\n",
    "        \n",
    "    res.index = pd.MultiIndex.from_tuples(res.index)\n",
    "    res.index.names = ['pair1', 'pair2']\n",
    "    res.reset_index(inplace=True)\n",
    "    \n",
    "    current_iv_df = pd.DataFrame.from_dict(current_iv_dict, 'index')\n",
    "\n",
    "    res = res.join(current_iv_df, on='pair1')\n",
    "    res = res.join(current_iv_df, on='pair2', rsuffix='2')\n",
    "\n",
    "    res = res.rename(columns={'0':'iv1', '02':'iv2'})\n",
    "\n",
    "    res.set_index(['pair1','pair2'], inplace=True)\n",
    "    corr_df.index.names = ['pair1', 'pair2']\n",
    "    res = res.join(corr_df)\n",
    "\n",
    "\n",
    "    res = res.sort_values(by='zscore', ascending=False, key=abs)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_vrp_ratio_ranks(vrp_ratio_df: pd.DataFrame, rv_df: pd.DataFrame, corr_df: pd.DataFrame, stockpx_df: pd.DataFrame,\n",
    "                         dte: int=30, strike_count: int=2, volume_lookback: int=1, dte_threshold: int=20, z_window: int=100, use_vrp_df: bool=False, vrp_df=None):\n",
    "\n",
    "\n",
    "\n",
    "    tickers = np.unique(np.append(vrp_ratio_df.columns.to_frame()[0].values, vrp_ratio_df.columns.to_frame()[1].values))\n",
    "    current_vrp_dict = {}\n",
    "    \n",
    "    if use_vrp_df:\n",
    "        current_vrp_dict = vrp_df.iloc[-1,:].T.to_dict()\n",
    "    else:\n",
    "        for ticker in tqdm(tickers):\n",
    "            print(ticker)\n",
    "            current_vrp_dict[ticker] = get_current_iv(ticker, dte=dte, strike_count=strike_count, \n",
    "                                                      volume_lookback=volume_lookback, dte_threshold=dte_threshold)*100/rv_df[ticker][-1]\n",
    "            clear_output()\n",
    "\n",
    "\n",
    "    ratio_dict = {}\n",
    "    zscore_dict = {}\n",
    "    pctl_dict = {}\n",
    "    beta_dict = {}\n",
    "    beta_premium_dict = {}\n",
    "    for pair in vrp_ratio_df.columns:\n",
    "        ratio_dict[pair] = current_vrp_dict[pair[0]]/current_vrp_dict[pair[1]]\n",
    "        zscore_dict[pair] = (ratio_dict[pair] - vrp_ratio_df[pair][-z_window:].mean())/(vrp_ratio_df[pair][-z_window:].std())\n",
    "        pctl_dict[pair] = scipy.stats.percentileofscore(vrp_ratio_df[pair][~np.isnan(vrp_ratio_df[pair])], \n",
    "                                                                        ratio_dict[pair], 'weak')\n",
    "        beta_dict[pair] = (abs(stockpx_df[pair[0]].pct_change()/stockpx_df[pair[1]].pct_change())).replace([np.inf,-np.inf], np.nan).mean()\n",
    "        beta_premium_dict[pair] = abs(current_vrp_dict[pair[1]] - current_vrp_dict[pair[0]]*beta_dict[pair])\n",
    "\n",
    "\n",
    "    current_ratio_df = pd.DataFrame.from_dict(ratio_dict, 'index', columns=['vrp_ratio'])\n",
    "    zscore_df = pd.DataFrame.from_dict(zscore_dict, 'index', columns=['zscore'])\n",
    "    pctl_df = pd.DataFrame.from_dict(pctl_dict, 'index', columns=['pctl'])\n",
    "    if stockpx_df is not None:\n",
    "        beta_df = pd.DataFrame.from_dict(beta_dict, 'index', columns=['beta'])\n",
    "        beta_premium_df = pd.DataFrame.from_dict(beta_premium_dict, 'index', columns=['beta_premium'])\n",
    "\n",
    "    if stockpx_df is not None:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df, beta_df, beta_premium_df], axis=1, join='inner')\n",
    "    else:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df], axis=1, join='inner')\n",
    "        \n",
    "    res.index = pd.MultiIndex.from_tuples(res.index)\n",
    "    res.index.names = ['pair1', 'pair2']\n",
    "    res.reset_index(inplace=True)\n",
    "    \n",
    "    current_iv_df = pd.DataFrame.from_dict(current_vrp_dict, 'index')\n",
    "\n",
    "    res = res.join(current_iv_df, on='pair1')\n",
    "    res = res.join(current_iv_df, on='pair2', rsuffix='2')\n",
    "\n",
    "    res = res.rename(columns={'0':'vrp1', '02':'vrp2'})\n",
    "\n",
    "    res.set_index(['pair1','pair2'], inplace=True)\n",
    "    corr_df.index.names = ['pair1', 'pair2']\n",
    "    res = res.join(corr_df)\n",
    "\n",
    "\n",
    "    res = res.sort_values(by='zscore', ascending=False, key=abs)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iv_ratios(ranks_df: pd.Series or pd.DataFrame, iv_ratio_df: pd.DataFrame or pd.Series, iv_df: pd.DataFrame or pd.Series, n:int=100,\n",
    "                   z_window: int=100, z_threshold: float=3.0, interactive: bool=False, write_to_file: bool=True, title: str='IV30', use_df: bool=False):\n",
    "\n",
    "    ranks_df = ranks_df[:n]\n",
    "    ranks_df = ranks_df[ranks_df['zscore'].abs() >= z_threshold]\n",
    "\n",
    "    iv_ratio_df = iv_ratio_df.T\n",
    "    iv_ratio_df.index.names = ['pair1','pair2']\n",
    "    \n",
    "\n",
    "\n",
    "    if isinstance(ranks_df.index,pd.MultiIndex):\n",
    "        pairs = (ranks_df.index.to_frame()['pair1'] + '/' + ranks_df.index.to_frame()['pair2'])\n",
    "\n",
    "\n",
    "    if use_df:\n",
    "        td = iv_df.index[-1]\n",
    "        iv_mult=1\n",
    "    else:\n",
    "        td = datetime.today().replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "        iv_mult=100\n",
    "    \n",
    "    currivratios = ranks_df['iv_ratio'].rename(td)\n",
    "\n",
    "    iv_ratio_df = iv_ratio_df.join(currivratios, how='inner').T\n",
    "\n",
    "    \n",
    "    currivs = pd.concat([ranks_df.reset_index()[['pair1','iv1']], \n",
    "                         ranks_df.reset_index()[['pair2','iv2']]\n",
    "                         .rename(columns={'pair2':'pair1', 'iv2':'iv1'})]).drop_duplicates().set_index('pair1')\n",
    "    \n",
    "    currivs = (currivs.rename(columns={'iv1': td}).T*iv_mult).round(2)\n",
    "    \n",
    "    iv_df = pd.concat([iv_df, currivs], axis=0, join='inner')\n",
    "\n",
    "    \n",
    "    f = make_subplots(rows=2,cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "    for pair in pairs:\n",
    "        s1, s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        mean = [iv_ratio_df[(s1,s2)][-z_window:].mean()]*len(iv_ratio_df.index)\n",
    "        sd_upper_2 = mean + 2*iv_ratio_df[(s1,s2)][-z_window:].std()\n",
    "        sd_lower_2 = mean - 2*iv_ratio_df[(s1,s2)][-z_window:].std()\n",
    "\n",
    "\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=iv_ratio_df[(s1,s2)], name=pair, visible=False,showlegend=False, line=dict(color='blue')), row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=mean, line=dict(color='black',dash='dash'), name='mean', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=sd_lower_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_lower_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=sd_upper_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_upper_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=iv_df[s1], name=s1, visible=False,showlegend=False, line=dict(color='red')), row=2,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=iv_df[s2], name=s2, visible=False,showlegend=False, line=dict(color='orange')), row=2,col=1)\n",
    "        f.add_scatter(x=[iv_ratio_df.index[-1]], y=[iv_ratio_df[(s1,s2)][-1]], mode='text', text=round(iv_ratio_df[(s1,s2)][-1],2), textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='blue'), row=1,col=1)\n",
    "        f.add_scatter(x=[iv_ratio_df.index[-1]], y=[iv_df[s1][-1]], mode='text', text=iv_df[s1][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='red'), row=2,col=1)\n",
    "        f.add_scatter(x=[iv_ratio_df.index[-1]], y=[iv_df[s2][-1]], mode='text', text=iv_df[s2][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='orange'), row=2,col=1)\n",
    "\n",
    "\n",
    "    buttons = []\n",
    "\n",
    "    ind = range(len(pairs)) \n",
    "    for i,pair in enumerate(pairs):\n",
    "        t_ind = [i*9,i*9+1,i*9+2,i*9+3,i*9+4,i*9+5,i*9+6,i*9+7,i*9+8]\n",
    "        t_ind_2 = [i*9,i*9+4,i*9+5]\n",
    "        s1,s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        try:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r'],2)\n",
    "        except KeyError:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r(S)'],2)\n",
    "        try:\n",
    "            beta = round(ranks_df.loc[(s1,s2),'beta'],2)\n",
    "        except KeyError:\n",
    "            beta = None\n",
    "        z = round(ranks_df.loc[(s1,s2), 'zscore'],2)\n",
    "        pctl = int(round(np.nan_to_num(ranks_df.loc[(s1,s2), 'pctl'],0.0), 0))\n",
    "        buttons.append(\n",
    "            dict(\n",
    "                method='update',\n",
    "                label = pair,\n",
    "                visible=True,\n",
    "                args=[\n",
    "                    {'visible': [(i in t_ind) for i,x in enumerate(f.data)],\n",
    "                     'showlegend': [(i in t_ind_2) for i,x in enumerate(f.data)]},\n",
    "                     {'title': {'text': f'{pair} {title}: R = {corr}, Z = {z}, %tile = {pctl}, Beta = {beta}', 'y': 1.1, 'x': 0.8, 'xanchor': 'right', 'yanchor': 'top'}},\n",
    "                ]\n",
    "                    \n",
    "            )\n",
    "        )\n",
    "\n",
    "    f.update_layout(updatemenus=[\n",
    "        dict(type='dropdown',\n",
    "            direction='right',\n",
    "            y=1.1,\n",
    "            xanchor='left',\n",
    "            yanchor='top',\n",
    "            showactive=False,\n",
    "            buttons=buttons)], hovermode='x unified', width=1800, height=900,margin=dict(l=5,r=5,t=10,b=5))\n",
    "\n",
    "\n",
    "    if interactive:\n",
    "        f.show()\n",
    "    \n",
    "    if write_to_file:\n",
    "        if not os.path.exists('IV_Plots'):\n",
    "            os.mkdir('IV_Plots')\n",
    "        f.write_html(f'IV_Plots/{title}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vrp_ratios(ranks_df: pd.Series or pd.DataFrame, vrp_ratio_df: pd.DataFrame or pd.Series, vrp_df: pd.DataFrame or pd.Series, n:int=100,\n",
    "                   z_window: int=100, z_threshold: float = 3.0, interactive: bool=False, write_to_file: bool=True, title: str='VRP30', use_df: bool=False):\n",
    "\n",
    "    ranks_df = ranks_df[:n]\n",
    "    ranks_df = ranks_df[ranks_df['zscore'].abs() >= z_threshold]\n",
    "    \n",
    "    vrp_ratio_df = vrp_ratio_df.T\n",
    "    vrp_ratio_df.index.names = ['pair1','pair2']\n",
    "\n",
    "\n",
    "    if isinstance(ranks_df.index,pd.MultiIndex):\n",
    "        pairs = (ranks_df.index.to_frame()['pair1'] + '/' + ranks_df.index.to_frame()['pair2'])\n",
    "\n",
    "\n",
    "    if use_df:\n",
    "        td = vrp_df.index[-1]\n",
    "    else:\n",
    "        td = datetime.today().replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "    \n",
    "    currvrpratios = ranks_df['vrp_ratio'].rename(td)\n",
    "\n",
    "    vrp_ratio_df = vrp_ratio_df.join(currvrpratios, how='inner').T\n",
    "\n",
    "    \n",
    "    currvrps = pd.concat([ranks_df.reset_index()[['pair1','vrp1']], \n",
    "                         ranks_df.reset_index()[['pair2','vrp2']]\n",
    "                         .rename(columns={'pair2':'pair1', 'vrp2':'vrp1'})]).drop_duplicates().set_index('pair1')\n",
    "    \n",
    "    currvrps = (currvrps.rename(columns={'vrp1': td}).T).round(2)\n",
    "    \n",
    "    vrp_df = pd.concat([vrp_df, currvrps], axis=0, join='inner')\n",
    "\n",
    "    \n",
    "    f = make_subplots(rows=2,cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "    for pair in pairs:\n",
    "        s1, s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        mean = [vrp_ratio_df[(s1,s2)][-z_window:].mean()]*len(vrp_ratio_df.index)\n",
    "        sd_upper_2 = mean + 2*vrp_ratio_df[(s1,s2)][-z_window:].std()\n",
    "        sd_lower_2 = mean - 2*vrp_ratio_df[(s1,s2)][-z_window:].std()\n",
    "\n",
    "\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=vrp_ratio_df[(s1,s2)], name=pair, visible=False,showlegend=False, line=dict(color='blue')), row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=mean, line=dict(color='black',dash='dash'), name='mean', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=sd_lower_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_lower_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=sd_upper_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_upper_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=vrp_df[s1], name=s1, visible=False,showlegend=False, line=dict(color='red')), row=2,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=vrp_df[s2], name=s2, visible=False,showlegend=False, line=dict(color='orange')), row=2,col=1)\n",
    "        f.add_scatter(x=[vrp_ratio_df.index[-1]], y=[vrp_ratio_df[(s1,s2)][-1]], mode='text', text=round(vrp_ratio_df[(s1,s2)][-1],2), textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='blue'), row=1,col=1)\n",
    "        f.add_scatter(x=[vrp_ratio_df.index[-1]], y=[vrp_df[s1][-1]], mode='text', text=vrp_df[s1][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='red'), row=2,col=1)\n",
    "        f.add_scatter(x=[vrp_ratio_df.index[-1]], y=[vrp_df[s2][-1]], mode='text', text=vrp_df[s2][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='orange'), row=2,col=1)\n",
    "\n",
    "\n",
    "    buttons = []\n",
    "\n",
    "    ind = range(len(pairs)) \n",
    "    for i,pair in enumerate(pairs):\n",
    "        t_ind = [i*9,i*9+1,i*9+2,i*9+3,i*9+4,i*9+5,i*9+6,i*9+7,i*9+8]\n",
    "        t_ind_2 = [i*9,i*9+4,i*9+5]\n",
    "        s1,s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        try:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r(VRP)'],2)\n",
    "        except KeyError:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r(S)'],2)\n",
    "        try:\n",
    "            beta = round(ranks_df.loc[(s1,s2),'beta'],2)\n",
    "        except KeyError:\n",
    "            beta = None\n",
    "        z = round(ranks_df.loc[(s1,s2), 'zscore'],2)\n",
    "        pctl = int(round(ranks_df.loc[(s1,s2), 'pctl'], 0))\n",
    "        buttons.append(\n",
    "            dict(\n",
    "                method='update',\n",
    "                label = pair,\n",
    "                visible=True,\n",
    "                args=[\n",
    "                    {'visible': [(i in t_ind) for i,x in enumerate(f.data)],\n",
    "                     'showlegend': [(i in t_ind_2) for i,x in enumerate(f.data)]},\n",
    "                     {'title': {'text': f'{pair} {title}: R = {corr}, Z = {z}, %tile = {pctl}, Beta = {beta}', 'y': 1.1, 'x': 0.8, 'xanchor': 'right', 'yanchor': 'top'}},\n",
    "                ]\n",
    "                    \n",
    "            )\n",
    "        )\n",
    "\n",
    "    f.update_layout(updatemenus=[\n",
    "        dict(type='dropdown',\n",
    "            direction='right',\n",
    "            y=1.1,\n",
    "            xanchor='left',\n",
    "            yanchor='top',\n",
    "            showactive=False,\n",
    "            buttons=buttons)], hovermode='x unified', width=1800, height=900,margin=dict(l=5,r=5,t=10,b=5))\n",
    "\n",
    "\n",
    "    if interactive:\n",
    "        f.show()\n",
    "    \n",
    "    if write_to_file:\n",
    "        if not os.path.exists('IV_Plots'):\n",
    "            os.mkdir('IV_Plots')\n",
    "        f.write_html(f'IV_Plots/{title}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yahoo_screener(url: str):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    driver.get(url + '?offset=0&count=100')\n",
    "    results = int(driver.find_element(By.CSS_SELECTOR, 'span[class=\"Mstart(15px) Fw(500) Fz(s)\"]').text.split(' ')[-2])\n",
    "    print(f'RESULTS: {results}')\n",
    "\n",
    "    offset=0\n",
    "    dfs = []\n",
    "    while offset < results: \n",
    "        print(f'PAGE {int((offset+100)/100)} of {results//100 + 1}')\n",
    "        driver.get(f'{url}?count=100&offset={offset}')\n",
    "        el=driver.find_element(By.CSS_SELECTOR, 'div[class=\"Ovx(a) Ovx(h)--print Ovy(h) W(100%) \"]')\n",
    "        dfs.append(pd.read_html(el.get_attribute('innerHTML'))[0])\n",
    "\n",
    "        offset+=100\n",
    "        clear_output()\n",
    "    driver.close()\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_next_x_days(days: int=7):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    dayrange = pd.date_range(datetime.today(), datetime.today()+timedelta(days))\n",
    "    start = datetime.strftime(dayrange[0],'%Y-%m-%d')\n",
    "    end = datetime.strftime(dayrange[-1],'%Y-%m-%d')\n",
    "\n",
    "    dfs_outer = []\n",
    "    for day in tqdm(dayrange):\n",
    "        day = datetime.strftime(day,'%Y-%m-%d')\n",
    "        driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}')\n",
    "        try:\n",
    "            results = int(driver.find_element(By.CSS_SELECTOR, 'span[class=\"Mstart(15px) Fw(500) Fz(s)\"]').text.split(' ')[-2])\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            continue\n",
    "\n",
    "        offset=0\n",
    "        dfs_inner = []\n",
    "        while offset < results: \n",
    "            driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}&offset={offset}')\n",
    "            try:\n",
    "                el=driver.find_element(By.CSS_SELECTOR, 'div[class=\"Ovx(a) Ovx(h)--print Ovy(h) W(100%) \"]')\n",
    "                dfs_inner.append(pd.read_html(el.get_attribute('innerHTML'))[0])\n",
    "            except selenium.common.exceptions.NoSuchElementException:\n",
    "                continue\n",
    "            \n",
    "            offset+=100\n",
    "\n",
    "        df_inner = pd.concat(dfs_inner)\n",
    "        df_inner['earnings_date'] = day\n",
    "        dfs_outer.append(df_inner)\n",
    "\n",
    "    df = pd.concat(dfs_outer).set_index('Symbol')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_last_x_days(days: int=7):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    dayrange = pd.date_range(datetime.today()-timedelta(days), datetime.today())\n",
    "    start = datetime.strftime(dayrange[0],'%Y-%m-%d')\n",
    "    end = datetime.strftime(dayrange[-1],'%Y-%m-%d')\n",
    "\n",
    "    dfs_outer = []\n",
    "    for day in tqdm(dayrange):\n",
    "        day = datetime.strftime(day,'%Y-%m-%d')\n",
    "        driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}')\n",
    "        try:\n",
    "            results = int(driver.find_element(By.CSS_SELECTOR, 'span[class=\"Mstart(15px) Fw(500) Fz(s)\"]').text.split(' ')[-2])\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            continue\n",
    "\n",
    "        offset=0\n",
    "        dfs_inner = []\n",
    "        while offset < results: \n",
    "            driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}&offset={offset}')\n",
    "            try:\n",
    "                el=driver.find_element(By.CSS_SELECTOR, 'div[class=\"Ovx(a) Ovx(h)--print Ovy(h) W(100%) \"]')\n",
    "                dfs_inner.append(pd.read_html(el.get_attribute('innerHTML'))[0])\n",
    "            except selenium.common.exceptions.NoSuchElementException:\n",
    "                continue\n",
    "            \n",
    "            offset+=100\n",
    "\n",
    "        df_inner = pd.concat(dfs_inner)\n",
    "        df_inner['earnings_date'] = day\n",
    "        dfs_outer.append(df_inner)\n",
    "\n",
    "    df = pd.concat(dfs_outer).set_index('Symbol')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_tickers(yahoo_screen_url: str, etf_screen_url: str, earnings_days_forward: int=7, earnings_days_back: int=7, etf_limit: int=50):\n",
    "    apikey = os.environ['ndl_api_key']\n",
    "    r = requests.get(f'https://data.nasdaq.com/api/v3/databases/OPT/metadata?api_key={apikey}', stream=True)\n",
    "    z = zipfile.ZipFile(BytesIO(r.content))\n",
    "    z.extractall(path='')\n",
    "\n",
    "    tickers_avail = pd.read_csv('OPT_metadata.csv', index_col=0)\n",
    "    tickers_avail = tickers_avail[pd.to_datetime(tickers_avail['refreshed_at']) >= datetime.today()-BDay(2)]\n",
    "\n",
    "    yf_screen = scrape_yahoo_screener(yahoo_screen_url)['Symbol'].to_list()\n",
    "\n",
    "    if earnings_days_forward > 0:\n",
    "        earnings_next_x = get_earnings_next_x_days(earnings_days_forward)\n",
    "    else:\n",
    "        earnings_next_x = []\n",
    "\n",
    "    if earnings_days_back > 0:\n",
    "        earnings_last_x = get_earnings_last_x_days(earnings_days_back)\n",
    "    else:\n",
    "        earnings_last_x = []\n",
    "\n",
    "    earnings_next_30 = earnings_next_x[pd.to_datetime(earnings_next_x['earnings_date']) <= datetime.today() + timedelta(30)].index.to_list()\n",
    "    earnings_next_60 = earnings_next_x[pd.to_datetime(earnings_next_x['earnings_date']) <= datetime.today() + timedelta(60)].index.to_list()\n",
    "    earnings_next_90 = earnings_next_x.index.to_list()\n",
    "\n",
    "    ivticks_30 = [x for x in yf_screen if x in tickers_avail.index and x not in earnings_next_30]  \n",
    "    ivticks_60 = [x for x in yf_screen if x in tickers_avail.index and x not in earnings_next_60]  \n",
    "    ivticks_90 = [x for x in yf_screen if x in tickers_avail.index and x not in earnings_next_90]  \n",
    "    vrpticks = [x for x in yf_screen if x in tickers_avail.index and x not in earnings_last_x]\n",
    "\n",
    "    if etf_limit > 0:\n",
    "        etfs = scrape_yahoo_screener(etf_screen_url)['Symbol'].to_list()[:etf_limit]\n",
    "        ivticks_30, ivticks_60, ivticks_90, = ivticks_30 + etfs, ivticks_60 + etfs, ivticks_90 + etfs\n",
    "        vrpticks = vrpticks + etfs\n",
    "        return list(ivticks_30), list(ivticks_60), list(ivticks_90), list(vrpticks)\n",
    "    else:\n",
    "        return list(ivticks_30), list(ivticks_60), list(ivticks_90), list(vrpticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hist_iv_data_from_csv(path):\n",
    "    dfdict = {}\n",
    "    for filename in os.listdir(path):\n",
    "        dfdict[filename.replace('.csv', '')] = pd.read_csv(os.path.join(path, filename), index_col=0)\n",
    "        dfdict[filename.replace('.csv', '')].index = pd.to_datetime(dfdict[filename.replace('.csv', '')].index)\n",
    "\n",
    "    return dfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_iv_csvs(basepath: str, rows=None, start_date = datetime.today()-timedelta(1), end_date = datetime.today(), keep: str='first'):\n",
    "\n",
    "\n",
    "    dfdict = {}\n",
    "    if rows is not None:\n",
    "        for file in ['stockpx', 'iv_30', 'iv_60', 'iv_90']: \n",
    "            dfdict[file] = pd.read_csv(os.path.join(basepath, f'{file}.csv'), index_col=0)\n",
    "            dfdict[file].index = pd.to_datetime(dfdict[file].index)\n",
    "    else:\n",
    "        for file in ['stockpx', 'iv_30', 'iv_60', 'iv_90']: \n",
    "            dfdict[file] = pd.read_csv(os.path.join(basepath, f'{file}.csv'), index_col=0)\n",
    "            dfdict[file].index = pd.to_datetime(dfdict[file].index)\n",
    "            dfdict[file] = dfdict[file].loc[:start_date - timedelta(1), :]\n",
    "\n",
    "    if rows is not None:\n",
    "        stockpx_append, iv30_append, iv60_append, iv90_append = get_hist_iv_data(list(dfdict['iv_30'].columns), rows=rows, write_to_file=False)\n",
    "    else:\n",
    "        stockpx_append, iv30_append, iv60_append, iv90_append = get_hist_iv_data(list(dfdict['iv_30'].columns), start_date=start_date, end_date=end_date, write_to_file=False)\n",
    "\n",
    "    stockpx_df = pd.concat([dfdict['stockpx'], stockpx_append], axis=0)\n",
    "    iv30_df = pd.concat([dfdict['iv_30'], iv30_append], axis=0)\n",
    "    iv60_df = pd.concat([dfdict['iv_60'], iv60_append], axis=0)\n",
    "    iv90_df = pd.concat([dfdict['iv_90'], iv90_append], axis=0)\n",
    "\n",
    "    stockpx_df = stockpx_df.dropna(axis=0, how='all')\n",
    "    iv30_df = iv30_df.dropna(axis=0, how='all')\n",
    "    iv60_df = iv60_df.dropna(axis=0, how='all')\n",
    "    iv90_df = iv90_df.dropna(axis=0, how='all')\n",
    "\n",
    "    stockpx_df = stockpx_df[~stockpx_df.index.duplicated(keep=keep)].sort_index()\n",
    "    iv30_df = iv30_df[~iv30_df.index.duplicated(keep=keep)].sort_index()\n",
    "    iv60_df = iv60_df[~iv60_df.index.duplicated(keep=keep)].sort_index()\n",
    "    iv90_df = iv90_df[~iv90_df.index.duplicated(keep=keep)].sort_index()\n",
    "\n",
    "\n",
    "    stockpx_df.to_csv(f'{basepath}/stockpx.csv')\n",
    "    iv30_df.to_csv(f'{basepath}/iv_30.csv')\n",
    "    iv60_df.to_csv(f'{basepath}/iv_60.csv')\n",
    "    iv90_df.to_csv(f'{basepath}/iv_90.csv')\n",
    "\n",
    "    dfdict = {'stockpx': stockpx_df, 'iv_30': iv30_df, 'iv_60': iv60_df, 'iv_90': iv90_df}\n",
    "\n",
    "    return dfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_plot_ratios(yahoo_screen_url: str, etf_screen_url: str, basepath: str, plot_vrp: bool=False, earnings_days_forward: int=7, earnings_days_back: int=7, rows: int=None, \n",
    "                            start_date=datetime.today()-timedelta(1), end_date=datetime.today(), \n",
    "                            corr_thresholds: tuple=(0.9,0.91,0.92,0.8,0.84,0.86), stockpx_threshold=2.0,  use_df=False, use_stockpx_corr=False, \n",
    "                            strike_count=2, volume_lookback: int=1, dte_threshold: int=20, z_window=100, z_threshold=3.0, plots_n=100, etf_limit: int=50, plot_titles=('IV30', 'IV60', 'IV90', 'VRP30', 'VRP60', 'VRP90')):\n",
    "\n",
    "    #earnings file\n",
    "    #https://www.barchart.com/stocks/earnings-within-7-days?viewName=main&orderBy=nextEarningsDate&orderDir=asc\n",
    "\n",
    "    if plot_vrp:\n",
    "        ivticks_30, ivticks_60, ivticks_90, vrpticks = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, earnings_days_forward=earnings_days_forward, \n",
    "                                                earnings_days_back=earnings_days_back, etf_limit=etf_limit)\n",
    "    else:\n",
    "        ivticks_30, ivticks_60, ivticks_90 = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, earnings_days_forward=earnings_days_forward, \n",
    "                                              earnings_days_back=0, etf_limit=etf_limit)[:3]\n",
    "\n",
    "    if rows is not None:\n",
    "        dfdict = update_iv_csvs(basepath, rows=rows)\n",
    "    else:\n",
    "        dfdict = update_iv_csvs(basepath, start_date=start_date, end_date=end_date)\n",
    "    \n",
    "\n",
    "    iv30_df = dfdict['iv_30']\n",
    "    iv60_df = dfdict['iv_60']\n",
    "    iv90_df = dfdict['iv_90']\n",
    "    stockpx_df = dfdict['stockpx']\n",
    "\n",
    "    rv_30 = get_rvs(stockpx_df,30)\n",
    "    rv_60 = get_rvs(stockpx_df,60)\n",
    "    rv_90 = get_rvs(stockpx_df,90)\n",
    "\n",
    "    if plot_vrp:\n",
    "        vrp_30 = get_vrps(stockpx_df, iv30_df, 30)\n",
    "        vrp_60 = get_vrps(stockpx_df, iv60_df, 60)\n",
    "        vrp_90 = get_vrps(stockpx_df, iv90_df, 90)\n",
    "\n",
    "\n",
    "    highcorrs_30, IV_ratios_30 = get_correlated_ivs(iv30_df, stockpx_df, corr_thresholds[0], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks_30)\n",
    "    highcorrs_60, IV_ratios_60 = get_correlated_ivs(iv60_df, stockpx_df, corr_thresholds[1], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks_60)\n",
    "    highcorrs_90, IV_ratios_90 = get_correlated_ivs(iv90_df, stockpx_df, corr_thresholds[2], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks_90)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        highvrpcorrs_30, VRP_ratios_30 = get_correlated_vrps(vrp_30, stockpx_df, corr_thresholds[3], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_60, VRP_ratios_60 = get_correlated_vrps(vrp_60, stockpx_df, corr_thresholds[4], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_90, VRP_ratios_90 = get_correlated_vrps(vrp_90, stockpx_df, corr_thresholds[5], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "    \n",
    "    ivranks_30 = get_current_iv_ratio_ranks(IV_ratios_30, highcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv30_df)\n",
    "    ivranks_60 = get_current_iv_ratio_ranks(IV_ratios_60, highcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv60_df)\n",
    "    ivranks_90 = get_current_iv_ratio_ranks(IV_ratios_90, highcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv90_df)\n",
    "\n",
    "    if plot_vrp:\n",
    "        vrpranks_30 = get_current_vrp_ratio_ranks(VRP_ratios_30, rv_30, highvrpcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_30)\n",
    "        vrpranks_60 = get_current_vrp_ratio_ranks(VRP_ratios_60, rv_60, highvrpcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_60)\n",
    "        vrpranks_90 = get_current_vrp_ratio_ranks(VRP_ratios_90, rv_90, highvrpcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_90)\n",
    "        \n",
    "    plot_iv_ratios(ivranks_30, IV_ratios_30, iv30_df, n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[0], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_60, IV_ratios_60, iv60_df, n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[1], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_90, IV_ratios_90, iv90_df, n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[2], use_df=use_df)\n",
    "\n",
    "    if plot_vrp:\n",
    "        plot_vrp_ratios(vrpranks_30, VRP_ratios_30, vrp_30,  n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[3], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_60, VRP_ratios_60, vrp_60,  n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[4], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_90, VRP_ratios_90, vrp_90,  n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[5], use_df=use_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_current_ratios(yahoo_screen_url: str, etf_screen_url: str, basepath: str, plot_vrp: bool=False, earnings_days_forward: int=7, earnings_days_back: int=7,\n",
    "                        corr_thresholds: tuple=(0.9,0.91,0.92,0.8,0.84,0.86), stockpx_threshold=2.0, use_df=False, use_stockpx_corr=False, \n",
    "                        strike_count=2, volume_lookback: int=1, dte_threshold: int=20, z_window=100, z_threshold=3.0, plots_n=100, etf_limit: int=50, \n",
    "                        plot_titles=('IV30', 'IV60', 'IV90', 'VRP30', 'VRP60', 'VRP90')):\n",
    "\n",
    "\n",
    "    if plot_vrp:\n",
    "        ivticks_30, ivticks_60, ivticks_90, vrpticks = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, \n",
    "                                            earnings_days_forward=earnings_days_forward, earnings_days_back=earnings_days_back, etf_limit=etf_limit)\n",
    "    else:\n",
    "        ivticks_30, ivticks_60, ivticks_90 = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, \n",
    "                                                        earnings_days_forward=earnings_days_forward, earnings_days_back=0, etf_limit=etf_limit)[:3]\n",
    "\n",
    "\n",
    "    dfdict = read_hist_iv_data_from_csv(basepath)\n",
    "    \n",
    "\n",
    "    iv30_df = dfdict['iv_30']\n",
    "    iv60_df = dfdict['iv_60']\n",
    "    iv90_df = dfdict['iv_90']\n",
    "    stockpx_df = dfdict['stockpx']\n",
    "\n",
    "    rv_30 = get_rvs(stockpx_df,30)\n",
    "    rv_60 = get_rvs(stockpx_df,60)\n",
    "    rv_90 = get_rvs(stockpx_df,90)\n",
    "\n",
    "    if plot_vrp:\n",
    "        vrp_30 = get_vrps(stockpx_df, iv30_df, 30)\n",
    "        vrp_60 = get_vrps(stockpx_df, iv60_df, 60)\n",
    "        vrp_90 = get_vrps(stockpx_df, iv90_df, 90)\n",
    "\n",
    "    highcorrs_30, IV_ratios_30 = get_correlated_ivs(iv30_df, stockpx_df, corr_thresholds[0], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks_30)\n",
    "    highcorrs_60, IV_ratios_60 = get_correlated_ivs(iv60_df, stockpx_df, corr_thresholds[1], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks_60)\n",
    "    highcorrs_90, IV_ratios_90 = get_correlated_ivs(iv90_df, stockpx_df, corr_thresholds[2], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks_90)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        highvrpcorrs_30, VRP_ratios_30 = get_correlated_vrps(vrp_30, stockpx_df, corr_thresholds[3], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_60, VRP_ratios_60 = get_correlated_vrps(vrp_60, stockpx_df, corr_thresholds[4], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_90, VRP_ratios_90 = get_correlated_vrps(vrp_90, stockpx_df, corr_thresholds[5], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        \n",
    "    \n",
    "    ivranks_30 = get_current_iv_ratio_ranks(IV_ratios_30, highcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold,\n",
    "                                            z_window=z_window, use_iv_df=use_df, iv_df=iv30_df)\n",
    "    ivranks_60 = get_current_iv_ratio_ranks(IV_ratios_60, highcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold,\n",
    "                                            z_window=z_window, use_iv_df=use_df, iv_df=iv60_df)\n",
    "    ivranks_90 = get_current_iv_ratio_ranks(IV_ratios_90, highcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold,\n",
    "                                            z_window=z_window, use_iv_df=use_df, iv_df=iv90_df)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        vrpranks_30 = get_current_vrp_ratio_ranks(VRP_ratios_30, rv_30, highvrpcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_30)\n",
    "        vrpranks_60 = get_current_vrp_ratio_ranks(VRP_ratios_60, rv_60, highvrpcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_60)\n",
    "        vrpranks_90 = get_current_vrp_ratio_ranks(VRP_ratios_90, rv_90, highvrpcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_90)\n",
    "\n",
    "    plot_iv_ratios(ivranks_30, IV_ratios_30, iv30_df, n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True ,title=plot_titles[0], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_60, IV_ratios_60, iv60_df, n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True ,title=plot_titles[1], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_90, IV_ratios_90, iv90_df, n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True ,title=plot_titles[2], use_df=use_df)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        plot_vrp_ratios(vrpranks_30, VRP_ratios_30, vrp_30,  n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[3], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_60, VRP_ratios_60, vrp_60,  n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[4], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_90, VRP_ratios_90, vrp_90,  n=plots_n, z_window=z_window, z_threshold=z_threshold, interactive=False, write_to_file=True, title=plot_titles[5], use_df=use_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
