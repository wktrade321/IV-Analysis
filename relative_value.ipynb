{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay\n",
    "from datetime import date, datetime, timedelta\n",
    "import time\n",
    "import yfinance as yf\n",
    "from pyetfdb_scraper import etf\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import nasdaqdatalink as ndl\n",
    "\n",
    "#TD Ameritrade API for historical equity prices and current quotes\n",
    "from tda.auth import easy_client\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import selenium.common.exceptions\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--start-maximized')\n",
    "chrome_options.page_load_strategy = 'normal'\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv('e.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize chromedriver function \n",
    "def driver():\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "#initialize TDA easy_client\n",
    "c = easy_client(\n",
    "    webdriver_func=driver,\n",
    "    api_key=os.environ['tda_api_key'],\n",
    "    redirect_uri='https://localhost',\n",
    "    token_path='token.json'\n",
    ")\n",
    "\n",
    "\n",
    "ndl.ApiConfig.api_key = os.environ['ndl_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_vix_contango():\n",
    "    index_text = ['Roll Yield','1-2','2-3','3-4','4-5','5-6','6-7','7-8']\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get('http://vixcentral.com')\n",
    "    \n",
    "    table = BeautifulSoup(driver.page_source).find_all('table')[0]\n",
    "    data = [x.text for x in table.find_all('td') if '%' in x.text]\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source).find_all('tspan', {'class': 'highcharts-text-outline'})\n",
    "    text = [x.text[:5] for x in soup]\n",
    "    vixspot, m1 = float(text[8]), float(text[0])\n",
    "    rollyield = str(round(100*(m1/vixspot - 1),2)) + '%'\n",
    "\n",
    "    data.insert(0,rollyield)\n",
    "\n",
    "    contango = pd.Series(data,index=index_text)\n",
    "    print('VIX Futures Curve Contango:')\n",
    "    print(contango)\n",
    "    return contango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_vix_contango(start_date: datetime, end_date: datetime, write_to_file: bool = True, output_path: str='VIX_Contango'):\n",
    "    \n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--start-maximized')\n",
    "    chrome_options.page_load_strategy = 'normal'\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get('http://vixcentral.com')\n",
    "\n",
    "    hist_prices_button = driver.find_element(by=By.XPATH, value='//*[@id=\"ui-id-9\"]')\n",
    "    hist_prices_button.click()\n",
    "\n",
    "    start_date_str = start_date.strftime('%B %d, %Y')\n",
    "\n",
    "\n",
    "    input = driver.find_element(by=By.XPATH, value='//*[@id=\"date1\"]')\n",
    "    input.clear()\n",
    "    input.send_keys(start_date_str)\n",
    "    button = driver.find_element(by=By.XPATH, value='//*[@id=\"b4\"]')\n",
    "    button.click()\n",
    "\n",
    "    current_date = start_date\n",
    "    datadict = {}\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        print(current_date)\n",
    "\n",
    "        if current_date.date() >= datetime.today().date() - timedelta(1):\n",
    "            break\n",
    "        table = BeautifulSoup(driver.page_source).find_all('table')[2]\n",
    "        data = [x.text for x in table.find_all('td')]\n",
    "        datadict[current_date] = data[:7]\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source).find_all('tspan', {'class': 'highcharts-text-outline'})\n",
    "        text = [x.text[:5] for x in soup]\n",
    "        m1 = float(text[16])\n",
    "\n",
    "        datadict[current_date].append(m1)\n",
    "\n",
    "        nextbutton = driver.find_element(By.XPATH, '//*[@id=\"bnext\"]')\n",
    "        nextbutton.click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        current_date_str = WebDriverWait(driver,1).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"date1\"]'))).get_property('value')\n",
    "        current_date = datetime.strptime(current_date_str, '%B %d, %Y')\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "    driver.close()\n",
    "    df = pd.DataFrame.from_dict(datadict,'index')\n",
    "    df = df.rename(columns={0:'1-2', 1:'2-3', 2:'3-4', 3:'4-5', 4:'5-6', 5:'6-7', 6:'7-8', 7:'M1'})\n",
    "\n",
    "    vixspot = yf.download('^VIX', start_date, end_date, interval='1d')['Close']\n",
    "\n",
    "    df = df.join(vixspot,how='left')\n",
    "\n",
    "    df['roll_yield'] = df['M1']/df['Close'] - 1\n",
    "\n",
    "    df = df.rename(columns={'Close': 'VIX_spot'})\n",
    "    \n",
    "    if write_to_file:\n",
    "        df.to_csv(f'{output_path}/vix_contango_{start_date.year}-{start_date.month}-{start_date.day}_{end_date.year}-{end_date.month}-{end_date.day}')\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iv_from_straddle(straddle_price: float, underlying_price: float, dte: int or float=30):\n",
    "    \"\"\"\n",
    "    #IV from straddle price - to be used when current IV data isn't avail\n",
    "    \"\"\"\n",
    "    res = (125*straddle_price)/(underlying_price*np.sqrt(dte/360))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_iv(symbol: str, dte: int=30, strike_count: int=2, volume_lookback: int=1, dte_threshold: int=20):\n",
    "    \"\"\"\n",
    "    get the current ATM implied volatility for a symbol and target DTE from yfinance. \n",
    "\n",
    "    :param dte: the target DTE of the options. The closest standard (monthly) expiration date to today+DTE is used\n",
    "    :param strike_count: how many of the closest ATM strikes are considered in the calc.\n",
    "    :param volume_lookback: number of trading days to look back for traded volume in the strikes being analyzed.\n",
    "                            if any of the strikes have no volume in the period, NaN is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    td = (datetime.today() - BDay(volume_lookback)).date()\n",
    "\n",
    "    try:\n",
    "        tk = yf.Ticker(symbol)\n",
    "    except KeyError:\n",
    "        time.sleep(2)\n",
    "        tk = yf.Ticker(symbol)\n",
    "    \n",
    "    try:\n",
    "        s = tk.info['currentPrice']\n",
    "    except KeyError:\n",
    "        s = tk.get_fast_info['lastPrice']\n",
    "\n",
    "    thirdfris = pd.date_range(td,td+timedelta(365),freq='WOM-3FRI')\n",
    "\n",
    "    if len(tk.options) > 0:\n",
    "        ds = [d for d in tk.options if d in thirdfris]\n",
    "        e = ds[pd.Series(abs((pd.to_datetime(ds) - datetime.today()).days - dte)).idxmin()]\n",
    "        if abs((pd.to_datetime(e) - datetime.today()).days - dte) > dte_threshold:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "    try: \n",
    "        calls = pd.DataFrame(tk.option_chain(e).calls)\n",
    "        puts = pd.DataFrame(tk.option_chain(e).puts)\n",
    "    except TypeError:\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            calls = pd.DataFrame(tk.option_chain(e).calls)\n",
    "            puts = pd.DataFrame(tk.option_chain(e).puts)\n",
    "        except TypeError:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "    \n",
    "    calls = calls[calls['strike'] >= s].sort_values(by='strike', key = lambda x: abs(x-s)).iloc[:strike_count,:]\n",
    "    puts = puts[puts['strike'] >= s].sort_values(by='strike', key = lambda x: abs(x-s)).iloc[:strike_count,:]\n",
    "\n",
    "\n",
    "    if (calls['lastTradeDate'].dt.date < td).any() or (puts['lastTradeDate'].dt.date < td).any():\n",
    "        return np.nan\n",
    "    \n",
    "    opts = pd.concat([calls, puts])\n",
    "\n",
    "    if datetime.today().hour >= 10:\n",
    "        return opts['impliedVolatility'].mean()\n",
    "    else: \n",
    "        straddle_price = opts['lastPrice'].mean()*2\n",
    "        dte_exact = (datetime.strptime(e,'%Y-%m-%d') - datetime.today()).days\n",
    "        return get_iv_from_straddle(straddle_price=straddle_price, underlying_price=s, dte=dte_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_iv_data(tickers_avail: list, start_date: datetime or datetime.date=datetime.today()-timedelta(365), end_date: datetime or datetime.date=datetime.today(),\n",
    "                rows: int=None, write_to_file: bool=False):\n",
    "    \"\"\" \n",
    "    pull historical daily IV data from the nasdaq data link series OPT for the provided list of tickers_avail. \n",
    "    If 'rows' is specified, pulls the last <rows> data points.\n",
    "    If not, then pulls data from <start_date> to <end_date>\n",
    "    \"\"\"\n",
    "    iv_dict = {}\n",
    "    if rows is None:\n",
    "        for ticker in tqdm(tickers_avail):\n",
    "            print(ticker)\n",
    "            iv_dict[ticker] = ndl.get(f'OPT/{ticker}', start_date=start_date, end_date=end_date)[['stockpx','iv30','iv60','iv90']]\n",
    "            clear_output()\n",
    "    else:\n",
    "        for ticker in tqdm(tickers_avail):\n",
    "            print(ticker)\n",
    "            iv_dict[ticker] = ndl.get(f'OPT/{ticker}', rows=rows)[['stockpx','iv30','iv60','iv90']]\n",
    "            clear_output()\n",
    "        \n",
    "    stockpx_df = pd.concat([iv_dict[ticker]['stockpx'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "    iv30_df = pd.concat([iv_dict[ticker]['iv30'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "    iv60_df = pd.concat([iv_dict[ticker]['iv60'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "    iv90_df = pd.concat([iv_dict[ticker]['iv90'].rename(ticker) for ticker in iv_dict.keys()], axis=1, join='outer')\n",
    "\n",
    "    if write_to_file:\n",
    "        path = f'IV_Data_{datetime.today().date()}'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        stockpx_df.to_csv(path+'/stockpx.csv')\n",
    "        iv30_df.to_csv(path+'/iv_30.csv')\n",
    "        iv60_df.to_csv(path+'/iv_60.csv')\n",
    "        iv90_df.to_csv(path+'/iv_90.csv')\n",
    "    return stockpx_df, iv30_df, iv60_df, iv90_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rvs(stockpx_df: pd.DataFrame, dte: int=30):\n",
    "    df = np.log(stockpx_df/stockpx_df.shift(1))\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.rolling(window=dte).std(ddof=0)*np.sqrt(252)*100\n",
    "    return df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vrps(stockpx_df: pd.DataFrame, iv_df: pd.DataFrame, dte: int=30):\n",
    "    rv_df = get_rvs(stockpx_df=stockpx_df, dte=dte)\n",
    "    vrp_df = (iv_df/rv_df).round(2)\n",
    "    return vrp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_ivs(iv_df, stockpx_df, corr_threshold: float, stockpx_threshold: float=2.0, use_iv_df: bool=False, use_stockpx_corr: bool=False, tickers=None):\n",
    "    tickers = [x for x in tickers if x in iv_df.columns]\n",
    "    iv_df = iv_df.loc[:,tickers]\n",
    "\n",
    "    \n",
    "    if use_iv_df:\n",
    "        iv_df = iv_df.iloc[:-1,:]\n",
    "\n",
    "\n",
    "    if use_stockpx_corr:\n",
    "        tickers = [x for x in tickers if x in stockpx_df.columns]    \n",
    "        stockpx_df = stockpx_df.loc[:,tickers]\n",
    "        corrs = stockpx_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r(S)')\n",
    "    else:\n",
    "        corrs = iv_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r')\n",
    "        \n",
    "    highcorrs = corrs[(corrs<1) & (corrs>corr_threshold)]\n",
    "    highcorrs.index.names = ['pair1', 'pair2']\n",
    "\n",
    "    highcorrs = pd.DataFrame(highcorrs)\n",
    "\n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair1').rename(columns={'0': 'stockpx_1'})\n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair2').rename(columns={'0': 'stockpx_2'})\n",
    "\n",
    "    highcorrs = highcorrs[(highcorrs['stockpx_1'] > stockpx_threshold) & (highcorrs['stockpx_2'] > stockpx_threshold)]\n",
    "\n",
    "    IV_ratios = pd.DataFrame({pair: iv_df[pair[0]]/iv_df[pair[1]] for pair in highcorrs.index})\n",
    "    \n",
    "    return highcorrs, IV_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_vrps(vrp_df, stockpx_df, corr_threshold: float, stockpx_threshold: float=2.0, \n",
    "                        use_vrp_df: bool=False, use_stockpx_corr: bool=False, tickers=None):\n",
    "    tickers = [x for x in tickers if x in vrp_df.columns]\n",
    "    vrp_df = vrp_df.loc[:,tickers]\n",
    "\n",
    "    \n",
    "    if use_vrp_df:\n",
    "        vrp_df = vrp_df.iloc[:-1,:]\n",
    "\n",
    "\n",
    "    if use_stockpx_corr:\n",
    "        tickers = [x for x in tickers if x in stockpx_df.columns]    \n",
    "        stockpx_df = stockpx_df.loc[:,tickers]\n",
    "        corrs = stockpx_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r(S)')\n",
    "    else:\n",
    "        corrs = vrp_df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates().rename('r(VRP)')\n",
    "    highcorrs = corrs[(corrs<1) & (corrs>corr_threshold)]\n",
    "    highcorrs.index.names = ['pair1', 'pair2']\n",
    "\n",
    "    highcorrs = pd.DataFrame(highcorrs)\n",
    "   \n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair1').rename(columns={'0': 'stockpx_1'})\n",
    "    highcorrs = highcorrs.join(stockpx_df.iloc[-1,:].rename('0'), on = 'pair2').rename(columns={'0': 'stockpx_2'})\n",
    "\n",
    "    highcorrs = highcorrs[(highcorrs['stockpx_1'] > stockpx_threshold) & (highcorrs['stockpx_2'] > stockpx_threshold)]\n",
    "\n",
    "    VRP_ratios = pd.DataFrame({pair: vrp_df[pair[0]]/vrp_df[pair[1]] for pair in highcorrs.index})\n",
    "    \n",
    "    return highcorrs, VRP_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_iv_ratio_ranks(iv_ratio_df: pd.DataFrame, corr_df:pd.DataFrame, stockpx_df: pd.DataFrame,\n",
    "                         dte: int=30, strike_count: int=2, volume_lookback: int=1, dte_threshold: int=20, z_window: int=100, use_iv_df: bool=False, iv_df=None):\n",
    "\n",
    "\n",
    "\n",
    "    tickers = np.unique(np.append(iv_ratio_df.columns.to_frame()[0].values, iv_ratio_df.columns.to_frame()[1].values))\n",
    "    current_iv_dict = {}\n",
    "    \n",
    "    if use_iv_df:\n",
    "        current_iv_dict = iv_df.iloc[-1,:].T.to_dict()\n",
    "    else:\n",
    "        for ticker in tqdm(tickers):\n",
    "            print(ticker)\n",
    "            current_iv_dict[ticker] = get_current_iv(ticker, dte=dte, strike_count=strike_count, volume_lookback=volume_lookback, dte_threshold=dte_threshold)\n",
    "            clear_output()\n",
    "\n",
    "\n",
    "    ratio_dict = {}\n",
    "    zscore_dict = {}\n",
    "    pctl_dict = {}\n",
    "    beta_dict = {}\n",
    "    beta_premium_dict = {}\n",
    "    for pair in iv_ratio_df.columns:\n",
    "        ratio_dict[pair] = current_iv_dict[pair[0]]/current_iv_dict[pair[1]]\n",
    "        zscore_dict[pair] = (ratio_dict[pair] - iv_ratio_df[pair][-z_window:].mean())/(iv_ratio_df[pair][-z_window:].std())\n",
    "        pctl_dict[pair] = scipy.stats.percentileofscore(iv_ratio_df[pair][~np.isnan(iv_ratio_df[pair])], \n",
    "                                                                        ratio_dict[pair], 'weak')\n",
    "        beta_dict[pair] = (abs(stockpx_df[pair[0]].pct_change()/stockpx_df[pair[1]].pct_change())).replace([np.inf,-np.inf], np.nan).mean()\n",
    "        beta_premium_dict[pair] = abs(current_iv_dict[pair[1]] - current_iv_dict[pair[0]]*beta_dict[pair])\n",
    "\n",
    "\n",
    "    current_ratio_df = pd.DataFrame.from_dict(ratio_dict, 'index', columns=['iv_ratio'])\n",
    "    zscore_df = pd.DataFrame.from_dict(zscore_dict, 'index', columns=['zscore'])\n",
    "    pctl_df = pd.DataFrame.from_dict(pctl_dict, 'index', columns=['pctl'])\n",
    "    if stockpx_df is not None:\n",
    "        beta_df = pd.DataFrame.from_dict(beta_dict, 'index', columns=['beta'])\n",
    "        beta_premium_df = pd.DataFrame.from_dict(beta_premium_dict, 'index', columns=['beta_premium'])\n",
    "\n",
    "    if stockpx_df is not None:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df, beta_df, beta_premium_df], axis=1, join='inner')\n",
    "    else:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df], axis=1, join='inner')\n",
    "        \n",
    "    res.index = pd.MultiIndex.from_tuples(res.index)\n",
    "    res.index.names = ['pair1', 'pair2']\n",
    "    res.reset_index(inplace=True)\n",
    "    \n",
    "    current_iv_df = pd.DataFrame.from_dict(current_iv_dict, 'index')\n",
    "\n",
    "    res = res.join(current_iv_df, on='pair1')\n",
    "    res = res.join(current_iv_df, on='pair2', rsuffix='2')\n",
    "\n",
    "    res = res.rename(columns={'0':'iv1', '02':'iv2'})\n",
    "\n",
    "    res.set_index(['pair1','pair2'], inplace=True)\n",
    "    corr_df.index.names = ['pair1', 'pair2']\n",
    "    res = res.join(corr_df)\n",
    "\n",
    "\n",
    "    res = res.sort_values(by='zscore', ascending=False, key=abs)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_vrp_ratio_ranks(vrp_ratio_df: pd.DataFrame, rv_df: pd.DataFrame, corr_df: pd.DataFrame, stockpx_df: pd.DataFrame,\n",
    "                         dte: int=30, strike_count: int=2, volume_lookback: int=1, dte_threshold: int=20, z_window: int=100, use_vrp_df: bool=False, vrp_df=None):\n",
    "\n",
    "\n",
    "\n",
    "    tickers = np.unique(np.append(vrp_ratio_df.columns.to_frame()[0].values, vrp_ratio_df.columns.to_frame()[1].values))\n",
    "    current_vrp_dict = {}\n",
    "    \n",
    "    if use_vrp_df:\n",
    "        current_vrp_dict = vrp_df.iloc[-1,:].T.to_dict()\n",
    "    else:\n",
    "        for ticker in tqdm(tickers):\n",
    "            print(ticker)\n",
    "            current_vrp_dict[ticker] = get_current_iv(ticker, dte=dte, strike_count=strike_count, \n",
    "                                                      volume_lookback=volume_lookback, dte_threshold=dte_threshold)*100/rv_df[ticker][-1]\n",
    "            clear_output()\n",
    "\n",
    "\n",
    "    ratio_dict = {}\n",
    "    zscore_dict = {}\n",
    "    pctl_dict = {}\n",
    "    beta_dict = {}\n",
    "    beta_premium_dict = {}\n",
    "    for pair in vrp_ratio_df.columns:\n",
    "        ratio_dict[pair] = current_vrp_dict[pair[0]]/current_vrp_dict[pair[1]]\n",
    "        zscore_dict[pair] = (ratio_dict[pair] - vrp_ratio_df[pair][-z_window:].mean())/(vrp_ratio_df[pair][-z_window:].std())\n",
    "        pctl_dict[pair] = scipy.stats.percentileofscore(vrp_ratio_df[pair][~np.isnan(vrp_ratio_df[pair])], \n",
    "                                                                        ratio_dict[pair], 'weak')\n",
    "        beta_dict[pair] = (abs(stockpx_df[pair[0]].pct_change()/stockpx_df[pair[1]].pct_change())).replace([np.inf,-np.inf], np.nan).mean()\n",
    "        beta_premium_dict[pair] = abs(current_vrp_dict[pair[1]] - current_vrp_dict[pair[0]]*beta_dict[pair])\n",
    "\n",
    "\n",
    "    current_ratio_df = pd.DataFrame.from_dict(ratio_dict, 'index', columns=['vrp_ratio'])\n",
    "    zscore_df = pd.DataFrame.from_dict(zscore_dict, 'index', columns=['zscore'])\n",
    "    pctl_df = pd.DataFrame.from_dict(pctl_dict, 'index', columns=['pctl'])\n",
    "    if stockpx_df is not None:\n",
    "        beta_df = pd.DataFrame.from_dict(beta_dict, 'index', columns=['beta'])\n",
    "        beta_premium_df = pd.DataFrame.from_dict(beta_premium_dict, 'index', columns=['beta_premium'])\n",
    "\n",
    "    if stockpx_df is not None:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df, beta_df, beta_premium_df], axis=1, join='inner')\n",
    "    else:\n",
    "        res = pd.concat([current_ratio_df, zscore_df, pctl_df], axis=1, join='inner')\n",
    "        \n",
    "    res.index = pd.MultiIndex.from_tuples(res.index)\n",
    "    res.index.names = ['pair1', 'pair2']\n",
    "    res.reset_index(inplace=True)\n",
    "    \n",
    "    current_iv_df = pd.DataFrame.from_dict(current_vrp_dict, 'index')\n",
    "\n",
    "    res = res.join(current_iv_df, on='pair1')\n",
    "    res = res.join(current_iv_df, on='pair2', rsuffix='2')\n",
    "\n",
    "    res = res.rename(columns={'0':'vrp1', '02':'vrp2'})\n",
    "\n",
    "    res.set_index(['pair1','pair2'], inplace=True)\n",
    "    corr_df.index.names = ['pair1', 'pair2']\n",
    "    res = res.join(corr_df)\n",
    "\n",
    "\n",
    "    res = res.sort_values(by='zscore', ascending=False, key=abs)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iv_ratios(ranks_df: pd.Series or pd.DataFrame, iv_ratio_df: pd.DataFrame or pd.Series, iv_df: pd.DataFrame or pd.Series, n:int=100,\n",
    "                   z_window: int=100, interactive: bool=False, write_to_file: bool=True, title: str='IV30', use_df: bool=False):\n",
    "\n",
    "    ranks_df = ranks_df[:n]\n",
    "    iv_ratio_df = iv_ratio_df.T\n",
    "    iv_ratio_df.index.names = ['pair1','pair2']\n",
    "\n",
    "\n",
    "    if isinstance(ranks_df.index,pd.MultiIndex):\n",
    "        pairs = (ranks_df.index.to_frame()['pair1'] + '/' + ranks_df.index.to_frame()['pair2'])\n",
    "\n",
    "\n",
    "    if use_df:\n",
    "        td = iv_df.index[-1]\n",
    "        iv_mult=1\n",
    "    else:\n",
    "        td = datetime.today().replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "        iv_mult=100\n",
    "    \n",
    "    currivratios = ranks_df['iv_ratio'].rename(td)\n",
    "\n",
    "    iv_ratio_df = iv_ratio_df.join(currivratios, how='inner').T\n",
    "\n",
    "    \n",
    "    currivs = pd.concat([ranks_df.reset_index()[['pair1','iv1']], \n",
    "                         ranks_df.reset_index()[['pair2','iv2']]\n",
    "                         .rename(columns={'pair2':'pair1', 'iv2':'iv1'})]).drop_duplicates().set_index('pair1')\n",
    "    \n",
    "    currivs = (currivs.rename(columns={'iv1': td}).T*iv_mult).round(2)\n",
    "    \n",
    "    iv_df = pd.concat([iv_df, currivs], axis=0, join='inner')\n",
    "\n",
    "    \n",
    "    f = make_subplots(rows=2,cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "    for pair in pairs:\n",
    "        s1, s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        mean = [iv_ratio_df[(s1,s2)][-z_window:].mean()]*len(iv_ratio_df.index)\n",
    "        sd_upper_2 = mean + 2*iv_ratio_df[(s1,s2)][-z_window:].std()\n",
    "        sd_lower_2 = mean - 2*iv_ratio_df[(s1,s2)][-z_window:].std()\n",
    "\n",
    "\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=iv_ratio_df[(s1,s2)], name=pair, visible=False,showlegend=False, line=dict(color='blue')), row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=mean, line=dict(color='black',dash='dash'), name='mean', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=sd_lower_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_lower_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=sd_upper_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_upper_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=iv_df[s1], name=s1, visible=False,showlegend=False, line=dict(color='red')), row=2,col=1)\n",
    "        f.add_trace(go.Scatter(x=iv_ratio_df.index, y=iv_df[s2], name=s2, visible=False,showlegend=False, line=dict(color='orange')), row=2,col=1)\n",
    "        f.add_scatter(x=[iv_ratio_df.index[-1]], y=[iv_ratio_df[(s1,s2)][-1]], mode='text', text=round(iv_ratio_df[(s1,s2)][-1],2), textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='blue'), row=1,col=1)\n",
    "        f.add_scatter(x=[iv_ratio_df.index[-1]], y=[iv_df[s1][-1]], mode='text', text=iv_df[s1][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='red'), row=2,col=1)\n",
    "        f.add_scatter(x=[iv_ratio_df.index[-1]], y=[iv_df[s2][-1]], mode='text', text=iv_df[s2][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='orange'), row=2,col=1)\n",
    "\n",
    "\n",
    "    buttons = []\n",
    "\n",
    "    ind = range(len(pairs)) \n",
    "    for i,pair in enumerate(pairs):\n",
    "        t_ind = [i*9,i*9+1,i*9+2,i*9+3,i*9+4,i*9+5,i*9+6,i*9+7,i*9+8]\n",
    "        t_ind_2 = [i*9,i*9+4,i*9+5]\n",
    "        s1,s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        try:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r'],2)\n",
    "        except KeyError:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r(S)'],2)\n",
    "        try:\n",
    "            beta = round(ranks_df.loc[(s1,s2),'beta'],2)\n",
    "        except KeyError:\n",
    "            beta = None\n",
    "        z = round(ranks_df.loc[(s1,s2), 'zscore'],2)\n",
    "        pctl = int(round(np.nan_to_num(ranks_df.loc[(s1,s2), 'pctl'],0.0), 0))\n",
    "        buttons.append(\n",
    "            dict(\n",
    "                method='update',\n",
    "                label = pair,\n",
    "                visible=True,\n",
    "                args=[\n",
    "                    {'visible': [(i in t_ind) for i,x in enumerate(f.data)],\n",
    "                     'showlegend': [(i in t_ind_2) for i,x in enumerate(f.data)]},\n",
    "                     {'title': {'text': f'{pair} {title}: R = {corr}, Z = {z}, %tile = {pctl}, Beta = {beta}', 'y': 1.1, 'x': 0.8, 'xanchor': 'right', 'yanchor': 'top'}},\n",
    "                ]\n",
    "                    \n",
    "            )\n",
    "        )\n",
    "\n",
    "    f.update_layout(updatemenus=[\n",
    "        dict(type='dropdown',\n",
    "            direction='right',\n",
    "            y=1.1,\n",
    "            xanchor='left',\n",
    "            yanchor='top',\n",
    "            showactive=False,\n",
    "            buttons=buttons)], hovermode='x unified', width=1800, height=900,margin=dict(l=5,r=5,t=10,b=5))\n",
    "\n",
    "\n",
    "    if interactive:\n",
    "        f.show()\n",
    "    \n",
    "    if write_to_file:\n",
    "        if not os.path.exists('IV_Plots'):\n",
    "            os.mkdir('IV_Plots')\n",
    "        f.write_html(f'IV_Plots/{title}_Ratios_{datetime.today().replace(microsecond=0)}.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vrp_ratios(ranks_df: pd.Series or pd.DataFrame, vrp_ratio_df: pd.DataFrame or pd.Series, vrp_df: pd.DataFrame or pd.Series, n:int=100,\n",
    "                   z_window: int=100, interactive: bool=False, write_to_file: bool=True, title: str='VRP30', use_df: bool=False):\n",
    "\n",
    "    ranks_df = ranks_df[:n]\n",
    "    vrp_ratio_df = vrp_ratio_df.T\n",
    "    vrp_ratio_df.index.names = ['pair1','pair2']\n",
    "\n",
    "\n",
    "    if isinstance(ranks_df.index,pd.MultiIndex):\n",
    "        pairs = (ranks_df.index.to_frame()['pair1'] + '/' + ranks_df.index.to_frame()['pair2'])\n",
    "\n",
    "\n",
    "    if use_df:\n",
    "        td = vrp_df.index[-1]\n",
    "    else:\n",
    "        td = datetime.today().replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "    \n",
    "    currvrpratios = ranks_df['vrp_ratio'].rename(td)\n",
    "\n",
    "    vrp_ratio_df = vrp_ratio_df.join(currvrpratios, how='inner').T\n",
    "\n",
    "    \n",
    "    currvrps = pd.concat([ranks_df.reset_index()[['pair1','vrp1']], \n",
    "                         ranks_df.reset_index()[['pair2','vrp2']]\n",
    "                         .rename(columns={'pair2':'pair1', 'vrp2':'vrp1'})]).drop_duplicates().set_index('pair1')\n",
    "    \n",
    "    currvrps = (currvrps.rename(columns={'vrp1': td}).T).round(2)\n",
    "    \n",
    "    vrp_df = pd.concat([vrp_df, currvrps], axis=0, join='inner')\n",
    "\n",
    "    \n",
    "    f = make_subplots(rows=2,cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "    for pair in pairs:\n",
    "        s1, s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        mean = [vrp_ratio_df[(s1,s2)][-z_window:].mean()]*len(vrp_ratio_df.index)\n",
    "        sd_upper_2 = mean + 2*vrp_ratio_df[(s1,s2)][-z_window:].std()\n",
    "        sd_lower_2 = mean - 2*vrp_ratio_df[(s1,s2)][-z_window:].std()\n",
    "\n",
    "\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=vrp_ratio_df[(s1,s2)], name=pair, visible=False,showlegend=False, line=dict(color='blue')), row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=mean, line=dict(color='black',dash='dash'), name='mean', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=sd_lower_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_lower_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=sd_upper_2, opacity=0.3, line=dict(color='black',dash='dash'), name='sd_upper_2', visible=False, showlegend=False) , row=1,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=vrp_df[s1], name=s1, visible=False,showlegend=False, line=dict(color='red')), row=2,col=1)\n",
    "        f.add_trace(go.Scatter(x=vrp_ratio_df.index, y=vrp_df[s2], name=s2, visible=False,showlegend=False, line=dict(color='orange')), row=2,col=1)\n",
    "        f.add_scatter(x=[vrp_ratio_df.index[-1]], y=[vrp_ratio_df[(s1,s2)][-1]], mode='text', text=round(vrp_ratio_df[(s1,s2)][-1],2), textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='blue'), row=1,col=1)\n",
    "        f.add_scatter(x=[vrp_ratio_df.index[-1]], y=[vrp_df[s1][-1]], mode='text', text=vrp_df[s1][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='red'), row=2,col=1)\n",
    "        f.add_scatter(x=[vrp_ratio_df.index[-1]], y=[vrp_df[s2][-1]], mode='text', text=vrp_df[s2][-1], textposition='top right', \n",
    "                      hoverinfo='skip', visible=False, textfont=dict(color='orange'), row=2,col=1)\n",
    "\n",
    "\n",
    "    buttons = []\n",
    "\n",
    "    ind = range(len(pairs)) \n",
    "    for i,pair in enumerate(pairs):\n",
    "        t_ind = [i*9,i*9+1,i*9+2,i*9+3,i*9+4,i*9+5,i*9+6,i*9+7,i*9+8]\n",
    "        t_ind_2 = [i*9,i*9+4,i*9+5]\n",
    "        s1,s2 = pair.split('/')[0], pair.split('/')[1]\n",
    "        try:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r(VRP)'],2)\n",
    "        except KeyError:\n",
    "            corr = round(ranks_df.loc[(s1,s2),'r(S)'],2)\n",
    "        try:\n",
    "            beta = round(ranks_df.loc[(s1,s2),'beta'],2)\n",
    "        except KeyError:\n",
    "            beta = None\n",
    "        z = round(ranks_df.loc[(s1,s2), 'zscore'],2)\n",
    "        pctl = int(round(ranks_df.loc[(s1,s2), 'pctl'], 0))\n",
    "        buttons.append(\n",
    "            dict(\n",
    "                method='update',\n",
    "                label = pair,\n",
    "                visible=True,\n",
    "                args=[\n",
    "                    {'visible': [(i in t_ind) for i,x in enumerate(f.data)],\n",
    "                     'showlegend': [(i in t_ind_2) for i,x in enumerate(f.data)]},\n",
    "                     {'title': {'text': f'{pair} {title}: R = {corr}, Z = {z}, %tile = {pctl}, Beta = {beta}', 'y': 1.1, 'x': 0.8, 'xanchor': 'right', 'yanchor': 'top'}},\n",
    "                ]\n",
    "                    \n",
    "            )\n",
    "        )\n",
    "\n",
    "    f.update_layout(updatemenus=[\n",
    "        dict(type='dropdown',\n",
    "            direction='right',\n",
    "            y=1.1,\n",
    "            xanchor='left',\n",
    "            yanchor='top',\n",
    "            showactive=False,\n",
    "            buttons=buttons)], hovermode='x unified', width=1800, height=900,margin=dict(l=5,r=5,t=10,b=5))\n",
    "\n",
    "\n",
    "    if interactive:\n",
    "        f.show()\n",
    "    \n",
    "    if write_to_file:\n",
    "        if not os.path.exists('IV_Plots'):\n",
    "            os.mkdir('IV_Plots')\n",
    "        f.write_html(f'IV_Plots/{title}_Ratios_{datetime.today().replace(microsecond=0)}.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_yahoo_screener(url: str):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    driver.get(url + '?offset=0&count=100')\n",
    "    results = int(driver.find_element(By.CSS_SELECTOR, 'span[class=\"Mstart(15px) Fw(500) Fz(s)\"]').text.split(' ')[-2])\n",
    "    print(f'RESULTS: {results}')\n",
    "\n",
    "    offset=0\n",
    "    dfs = []\n",
    "    while offset < results: \n",
    "        print(f'PAGE {int((offset+100)/100)} of {results//100 + 1}')\n",
    "        driver.get(f'{url}?count=100&offset={offset}')\n",
    "        el=driver.find_element(By.CSS_SELECTOR, 'div[class=\"Ovx(a) Ovx(h)--print Ovy(h) W(100%) \"]')\n",
    "        dfs.append(pd.read_html(el.get_attribute('innerHTML'))[0])\n",
    "\n",
    "        offset+=100\n",
    "        clear_output()\n",
    "    driver.close()\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_next_x_days(days: int=7):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    dayrange = pd.date_range(datetime.today(), datetime.today()+timedelta(days))\n",
    "    start = datetime.strftime(dayrange[0],'%Y-%m-%d')\n",
    "    end = datetime.strftime(dayrange[-1],'%Y-%m-%d')\n",
    "\n",
    "    dfs_outer = []\n",
    "    for day in tqdm(dayrange):\n",
    "        day = datetime.strftime(day,'%Y-%m-%d')\n",
    "        driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}')\n",
    "        try:\n",
    "            results = int(driver.find_element(By.CSS_SELECTOR, 'span[class=\"Mstart(15px) Fw(500) Fz(s)\"]').text.split(' ')[-2])\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            continue\n",
    "\n",
    "        offset=0\n",
    "        dfs_inner = []\n",
    "        while offset < results: \n",
    "            driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}&offset={offset}')\n",
    "            try:\n",
    "                el=driver.find_element(By.CSS_SELECTOR, 'div[class=\"Ovx(a) Ovx(h)--print Ovy(h) W(100%) \"]')\n",
    "                dfs_inner.append(pd.read_html(el.get_attribute('innerHTML'))[0])\n",
    "            except selenium.common.exceptions.NoSuchElementException:\n",
    "                continue\n",
    "            \n",
    "            offset+=100\n",
    "\n",
    "        df_inner = pd.concat(dfs_inner)\n",
    "        df_inner['earnings_date'] = day\n",
    "        dfs_outer.append(df_inner)\n",
    "\n",
    "    df = pd.concat(dfs_outer).set_index('Symbol')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_last_x_days(days: int=7):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    dayrange = pd.date_range(datetime.today()-timedelta(days), datetime.today())\n",
    "    start = datetime.strftime(dayrange[0],'%Y-%m-%d')\n",
    "    end = datetime.strftime(dayrange[-1],'%Y-%m-%d')\n",
    "\n",
    "    dfs_outer = []\n",
    "    for day in tqdm(dayrange):\n",
    "        day = datetime.strftime(day,'%Y-%m-%d')\n",
    "        driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}')\n",
    "        try:\n",
    "            results = int(driver.find_element(By.CSS_SELECTOR, 'span[class=\"Mstart(15px) Fw(500) Fz(s)\"]').text.split(' ')[-2])\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            continue\n",
    "\n",
    "        offset=0\n",
    "        dfs_inner = []\n",
    "        while offset < results: \n",
    "            driver.get(f'https://finance.yahoo.com/calendar/earnings?from={start}&to={end}&day={day}&offset={offset}')\n",
    "            try:\n",
    "                el=driver.find_element(By.CSS_SELECTOR, 'div[class=\"Ovx(a) Ovx(h)--print Ovy(h) W(100%) \"]')\n",
    "                dfs_inner.append(pd.read_html(el.get_attribute('innerHTML'))[0])\n",
    "            except selenium.common.exceptions.NoSuchElementException:\n",
    "                continue\n",
    "            \n",
    "            offset+=100\n",
    "\n",
    "        df_inner = pd.concat(dfs_inner)\n",
    "        df_inner['earnings_date'] = day\n",
    "        dfs_outer.append(df_inner)\n",
    "\n",
    "    df = pd.concat(dfs_outer).set_index('Symbol')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_tickers(yahoo_screen_url: str, etf_screen_url: str, earnings_days_forward: int=7, earnings_days_back: int=7, etf_limit: int=50):\n",
    "    apikey = os.environ['ndl_api_key']\n",
    "    r = requests.get(f'https://data.nasdaq.com/api/v3/databases/OPT/metadata?api_key={apikey}', stream=True)\n",
    "    z = zipfile.ZipFile(BytesIO(r.content))\n",
    "    z.extractall(path='')\n",
    "\n",
    "    tickers_avail = pd.read_csv('OPT_metadata.csv', index_col=0)\n",
    "    tickers_avail = tickers_avail[pd.to_datetime(tickers_avail['refreshed_at']) >= datetime.today()-BDay(2)]\n",
    "\n",
    "    yf_screen = scrape_yahoo_screener(yahoo_screen_url)['Symbol'].to_list()\n",
    "\n",
    "    if earnings_days_forward > 0:\n",
    "        earnings_next_x = get_earnings_next_x_days(earnings_days_forward).index.to_list()\n",
    "    else:\n",
    "        earnings_next_x = []\n",
    "\n",
    "    if earnings_days_back > 0:\n",
    "        earnings_last_x = get_earnings_last_x_days(earnings_days_back).index.to_list()\n",
    "    else:\n",
    "        earnings_last_x = []\n",
    "\n",
    "    ivticks = [x for x in yf_screen if x in tickers_avail.index and x not in earnings_next_x]  \n",
    "    vrpticks = [x for x in yf_screen if x in tickers_avail.index and x not in earnings_last_x]\n",
    "\n",
    "    if etf_limit > 0:\n",
    "        etfs = scrape_yahoo_screener(etf_screen_url)['Symbol'].to_list()[:etf_limit]\n",
    "        ivticks = ivticks + etfs\n",
    "        vrpticks = vrpticks + etfs\n",
    "        return list(ivticks), list(vrpticks)\n",
    "    else:\n",
    "        return list(ivticks), list(vrpticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hist_iv_data_from_csv(path):\n",
    "    dfdict = {}\n",
    "    for filename in os.listdir(path):\n",
    "        dfdict[filename.replace('.csv', '')] = pd.read_csv(os.path.join(path, filename), index_col=0)\n",
    "        dfdict[filename.replace('.csv', '')].index = pd.to_datetime(dfdict[filename.replace('.csv', '')].index)\n",
    "\n",
    "    return dfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_iv_csvs(basepath: str, rows=None, start_date = datetime.today()-timedelta(1), end_date = datetime.today(), keep: str='first'):\n",
    "\n",
    "\n",
    "    dfdict = {}\n",
    "    if rows is not None:\n",
    "        for file in ['stockpx', 'iv_30', 'iv_60', 'iv_90']: \n",
    "            dfdict[file] = pd.read_csv(os.path.join(basepath, f'{file}.csv'), index_col=0)\n",
    "            dfdict[file].index = pd.to_datetime(dfdict[file].index)\n",
    "    else:\n",
    "        for file in ['stockpx', 'iv_30', 'iv_60', 'iv_90']: \n",
    "            dfdict[file] = pd.read_csv(os.path.join(basepath, f'{file}.csv'), index_col=0)\n",
    "            dfdict[file].index = pd.to_datetime(dfdict[file].index)\n",
    "            dfdict[file] = dfdict[file].loc[:start_date - timedelta(1), :]\n",
    "\n",
    "    if rows is not None:\n",
    "        stockpx_append, iv30_append, iv60_append, iv90_append = get_hist_iv_data(list(dfdict['iv_30'].columns), rows=rows, write_to_file=False)\n",
    "    else:\n",
    "        stockpx_append, iv30_append, iv60_append, iv90_append = get_hist_iv_data(list(dfdict['iv_30'].columns), start_date=start_date, end_date=end_date, write_to_file=False)\n",
    "\n",
    "    stockpx_df = pd.concat([dfdict['stockpx'], stockpx_append], axis=0)\n",
    "    iv30_df = pd.concat([dfdict['iv_30'], iv30_append], axis=0)\n",
    "    iv60_df = pd.concat([dfdict['iv_60'], iv60_append], axis=0)\n",
    "    iv90_df = pd.concat([dfdict['iv_90'], iv90_append], axis=0)\n",
    "\n",
    "    stockpx_df = stockpx_df.dropna(axis=0, how='all')\n",
    "    iv30_df = iv30_df.dropna(axis=0, how='all')\n",
    "    iv60_df = iv60_df.dropna(axis=0, how='all')\n",
    "    iv90_df = iv90_df.dropna(axis=0, how='all')\n",
    "\n",
    "    stockpx_df = stockpx_df[~stockpx_df.index.duplicated(keep=keep)].sort_index()\n",
    "    iv30_df = iv30_df[~iv30_df.index.duplicated(keep=keep)].sort_index()\n",
    "    iv60_df = iv60_df[~iv60_df.index.duplicated(keep=keep)].sort_index()\n",
    "    iv90_df = iv90_df[~iv90_df.index.duplicated(keep=keep)].sort_index()\n",
    "\n",
    "\n",
    "    stockpx_df.to_csv(f'{basepath}/stockpx.csv')\n",
    "    iv30_df.to_csv(f'{basepath}/iv_30.csv')\n",
    "    iv60_df.to_csv(f'{basepath}/iv_60.csv')\n",
    "    iv90_df.to_csv(f'{basepath}/iv_90.csv')\n",
    "\n",
    "    dfdict = {'stockpx': stockpx_df, 'iv_30': iv30_df, 'iv_60': iv60_df, 'iv_90': iv90_df}\n",
    "\n",
    "    return dfdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_plot_ratios(yahoo_screen_url: str, etf_screen_url: str, basepath: str, plot_vrp: bool=False, earnings_days_forward: int=7, earnings_days_back: int=7, rows: int=None, \n",
    "                            start_date=datetime.today()-timedelta(1), end_date=datetime.today(), \n",
    "                            corr_thresholds: tuple=(0.9,0.91,0.92,0.8,0.84,0.86), stockpx_threshold=2.0,  use_df=False, use_stockpx_corr=False, \n",
    "                            strike_count=2, volume_lookback: int=1, dte_threshold: int=20, z_window=100, plots_n=100, etf_limit: int=50, plot_titles=('IV30', 'IV60', 'IV90', 'VRP30', 'VRP60', 'VRP90')):\n",
    "\n",
    "    #earnings file\n",
    "    #https://www.barchart.com/stocks/earnings-within-7-days?viewName=main&orderBy=nextEarningsDate&orderDir=asc\n",
    "\n",
    "    if plot_vrp:\n",
    "        ivticks, vrpticks = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, earnings_days_forward=earnings_days_forward, \n",
    "                                                earnings_days_back=earnings_days_back, etf_limit=etf_limit)\n",
    "    else:\n",
    "        ivticks = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, earnings_days_forward=earnings_days_forward, \n",
    "                                              earnings_days_back=0, etf_limit=etf_limit)[0]\n",
    "\n",
    "    if rows is not None:\n",
    "        dfdict = update_iv_csvs(basepath, rows=rows)\n",
    "    else:\n",
    "        dfdict = update_iv_csvs(basepath, start_date=start_date, end_date=end_date)\n",
    "    \n",
    "\n",
    "    iv30_df = dfdict['iv_30']\n",
    "    iv60_df = dfdict['iv_60']\n",
    "    iv90_df = dfdict['iv_90']\n",
    "    stockpx_df = dfdict['stockpx']\n",
    "\n",
    "    rv_30 = get_rvs(stockpx_df,30)\n",
    "    rv_60 = get_rvs(stockpx_df,60)\n",
    "    rv_90 = get_rvs(stockpx_df,90)\n",
    "\n",
    "    if plot_vrp:\n",
    "        vrp_30 = get_vrps(stockpx_df, iv30_df, 30)\n",
    "        vrp_60 = get_vrps(stockpx_df, iv60_df, 60)\n",
    "        vrp_90 = get_vrps(stockpx_df, iv90_df, 90)\n",
    "\n",
    "\n",
    "    highcorrs_30, IV_ratios_30 = get_correlated_ivs(iv30_df, stockpx_df, corr_thresholds[0], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks)\n",
    "    highcorrs_60, IV_ratios_60 = get_correlated_ivs(iv60_df, stockpx_df, corr_thresholds[1], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks)\n",
    "    highcorrs_90, IV_ratios_90 = get_correlated_ivs(iv90_df, stockpx_df, corr_thresholds[2], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        highvrpcorrs_30, VRP_ratios_30 = get_correlated_vrps(vrp_30, stockpx_df, corr_thresholds[3], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_60, VRP_ratios_60 = get_correlated_vrps(vrp_60, stockpx_df, corr_thresholds[4], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_90, VRP_ratios_90 = get_correlated_vrps(vrp_90, stockpx_df, corr_thresholds[5], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "    \n",
    "    ivranks_30 = get_current_iv_ratio_ranks(IV_ratios_30, highcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv30_df)\n",
    "    ivranks_60 = get_current_iv_ratio_ranks(IV_ratios_60, highcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv60_df)\n",
    "    ivranks_90 = get_current_iv_ratio_ranks(IV_ratios_90, highcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv90_df)\n",
    "\n",
    "    if plot_vrp:\n",
    "        vrpranks_30 = get_current_vrp_ratio_ranks(VRP_ratios_30, rv_30, highvrpcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_30)\n",
    "        vrpranks_60 = get_current_vrp_ratio_ranks(VRP_ratios_60, rv_60, highvrpcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_60)\n",
    "        vrpranks_90 = get_current_vrp_ratio_ranks(VRP_ratios_90, rv_90, highvrpcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_90)\n",
    "        \n",
    "    plot_iv_ratios(ivranks_30, IV_ratios_30, iv30_df, n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[0], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_60, IV_ratios_60, iv60_df, n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[1], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_90, IV_ratios_90, iv90_df, n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[2], use_df=use_df)\n",
    "\n",
    "    if plot_vrp:\n",
    "        plot_vrp_ratios(vrpranks_30, VRP_ratios_30, vrp_30,  n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[3], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_60, VRP_ratios_60, vrp_60,  n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[4], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_90, VRP_ratios_90, vrp_90,  n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[5], use_df=use_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_current_ratios(yahoo_screen_url: str, etf_screen_url: str, basepath: str, plot_vrp: bool=False, earnings_days_forward: int=7, earnings_days_back: int=7,\n",
    "                        corr_thresholds: tuple=(0.9,0.91,0.92,0.8,0.84,0.86), stockpx_threshold=2.0, use_df=False, use_stockpx_corr=False, \n",
    "                        strike_count=2, volume_lookback: int=1, dte_threshold: int=20, z_window=100, plots_n=100, etf_limit: int=50, \n",
    "                        plot_titles=('IV30', 'IV60', 'IV90', 'VRP30', 'VRP60', 'VRP90')):\n",
    "\n",
    "    #earnings file\n",
    "    #https://www.barchart.com/stocks/earnings-within-7-days?viewName=main&orderBy=nextEarningsDate&orderDir=asc\n",
    "\n",
    "    if plot_vrp:\n",
    "        ivticks, vrpticks = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, earnings_days_forward=earnings_days_forward, \n",
    "                                              earnings_days_back=earnings_days_back, etf_limit=etf_limit)\n",
    "    else:\n",
    "        ivticks = get_available_tickers(yahoo_screen_url=yahoo_screen_url, etf_screen_url=etf_screen_url, earnings_days_forward=earnings_days_forward, \n",
    "                                              earnings_days_back=0, etf_limit=etf_limit)[0]\n",
    "\n",
    "\n",
    "    dfdict = read_hist_iv_data_from_csv(basepath)\n",
    "    \n",
    "\n",
    "    iv30_df = dfdict['iv_30']\n",
    "    iv60_df = dfdict['iv_60']\n",
    "    iv90_df = dfdict['iv_90']\n",
    "    stockpx_df = dfdict['stockpx']\n",
    "\n",
    "    rv_30 = get_rvs(stockpx_df,30)\n",
    "    rv_60 = get_rvs(stockpx_df,60)\n",
    "    rv_90 = get_rvs(stockpx_df,90)\n",
    "\n",
    "    if plot_vrp:\n",
    "        vrp_30 = get_vrps(stockpx_df, iv30_df, 30)\n",
    "        vrp_60 = get_vrps(stockpx_df, iv60_df, 60)\n",
    "        vrp_90 = get_vrps(stockpx_df, iv90_df, 90)\n",
    "\n",
    "    highcorrs_30, IV_ratios_30 = get_correlated_ivs(iv30_df, stockpx_df, corr_thresholds[0], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks)\n",
    "    highcorrs_60, IV_ratios_60 = get_correlated_ivs(iv60_df, stockpx_df, corr_thresholds[1], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks)\n",
    "    highcorrs_90, IV_ratios_90 = get_correlated_ivs(iv90_df, stockpx_df, corr_thresholds[2], stockpx_threshold, \n",
    "                                                    use_iv_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers=ivticks)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        highvrpcorrs_30, VRP_ratios_30 = get_correlated_vrps(vrp_30, stockpx_df, corr_thresholds[3], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_60, VRP_ratios_60 = get_correlated_vrps(vrp_60, stockpx_df, corr_thresholds[4], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        highvrpcorrs_90, VRP_ratios_90 = get_correlated_vrps(vrp_90, stockpx_df, corr_thresholds[5], stockpx_threshold,  \n",
    "                                                            use_vrp_df=use_df, use_stockpx_corr=use_stockpx_corr, tickers = vrpticks)\n",
    "        \n",
    "    \n",
    "    ivranks_30 = get_current_iv_ratio_ranks(IV_ratios_30, highcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv30_df)\n",
    "    ivranks_60 = get_current_iv_ratio_ranks(IV_ratios_60, highcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv60_df)\n",
    "    ivranks_90 = get_current_iv_ratio_ranks(IV_ratios_90, highcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                            volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_iv_df=use_df, iv_df=iv90_df)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        vrpranks_30 = get_current_vrp_ratio_ranks(VRP_ratios_30, rv_30, highvrpcorrs_30, stockpx_df, dte=30, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_30)\n",
    "        vrpranks_60 = get_current_vrp_ratio_ranks(VRP_ratios_60, rv_60, highvrpcorrs_60, stockpx_df, dte=60, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_60)\n",
    "        vrpranks_90 = get_current_vrp_ratio_ranks(VRP_ratios_90, rv_90, highvrpcorrs_90, stockpx_df, dte=90, strike_count=strike_count, \n",
    "                                                  volume_lookback=volume_lookback, dte_threshold=dte_threshold, z_window=z_window, use_vrp_df=use_df, vrp_df=vrp_90)\n",
    "\n",
    "    plot_iv_ratios(ivranks_30, IV_ratios_30, iv30_df, n=plots_n, z_window=z_window, interactive=False, write_to_file=True ,title=plot_titles[0], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_60, IV_ratios_60, iv60_df, n=plots_n, z_window=z_window, interactive=False, write_to_file=True ,title=plot_titles[1], use_df=use_df)\n",
    "    plot_iv_ratios(ivranks_90, IV_ratios_90, iv90_df, n=plots_n, z_window=z_window, interactive=False, write_to_file=True ,title=plot_titles[2], use_df=use_df)\n",
    "    \n",
    "    if plot_vrp:\n",
    "        plot_vrp_ratios(vrpranks_30, VRP_ratios_30, vrp_30,  n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[3], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_60, VRP_ratios_60, vrp_60,  n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[4], use_df=use_df)\n",
    "        plot_vrp_ratios(vrpranks_90, VRP_ratios_90, vrp_90,  n=plots_n, z_window=z_window, interactive=False, write_to_file=True, title=plot_titles[5], use_df=use_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
